{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056eb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch torchvision torchaudio transformers datasets -y\n",
    "# !pip cache purge\n",
    "\n",
    "# # Install a compatible stack\n",
    "# !pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install transformers==4.41.2 datasets==2.19.2 rouge-score==0.1.2 scikit-learn matplotlib seaborn numpy tqdm\n",
    "# !pip install sentencepiece\n",
    "\n",
    "# Install Muon optimizer\n",
    "# !pip install git+https://github.com/KellerJordan/Muon.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6102d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from rouge_score import rouge_scorer\n",
    "from sacrebleu import corpus_bleu\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    MT5ForConditionalGeneration,\n",
    "    MT5Tokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "from muon import SingleDeviceMuonWithAuxAdam\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a547825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Muon LR: 0.015 (conservative for stable training with MoE)\n",
    "# - AdamW LR: 0.015 * 0.015 = 0.000225 (scaled down for embeddings/biases)\n",
    "OPTIMAL_MUON_LR = 0.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77aa2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    model_name = \"google/mt5-small\"\n",
    "\n",
    "    languages = [\"english\", \"hindi\", \"punjabi\"]\n",
    "    \n",
    "    # ===== MoE ARCHITECTURE =====\n",
    "    num_experts = 6\n",
    "    top_k = 2\n",
    "    capacity_factor = 1.0  # Minimum value to prevent routing overflow\n",
    "    expert_dropout = 0.1  # Optimal dropout value\n",
    "    \n",
    "    # ===== INPUT/OUTPUT LENGTHS =====\n",
    "    max_input_length = 512\n",
    "    max_target_length = 128\n",
    "\n",
    "    # ===== TRAINING HYPERPARAMETERS (OPTIMIZED) =====\n",
    "    batch_size = 16 \n",
    "    gradient_accumulation_steps = 4\n",
    "    learning_rate = 0.03  # Optimal LR found: 3.00e-02\n",
    "    num_epochs = 10  # Full training\n",
    "    warmup_steps = 2000 \n",
    "    weight_decay = 0.01  \n",
    "    optimizer = \"muon\"\n",
    "    use_amp = False  # Disabled for FP32 stability\n",
    "    \n",
    "    # ===== CURRICULUM LEARNING =====\n",
    "    use_curriculum = True\n",
    "    curriculum_phases = [\n",
    "        {\"name\": \"Phase 1: Shortest\", \"epochs\": 2, \"max_input_len\": 128, \"max_target_len\": 32},\n",
    "        {\"name\": \"Phase 2: Short\", \"epochs\": 3, \"max_input_len\": 256, \"max_target_len\": 64},\n",
    "        {\"name\": \"Phase 3: Medium\", \"epochs\": 3, \"max_input_len\": 384, \"max_target_len\": 96},\n",
    "        {\"name\": \"Phase 4: Long\", \"epochs\": 2, \"max_input_len\": 512, \"max_target_len\": 128}\n",
    "    ]\n",
    "    \n",
    "    # ===== LENGTH-BALANCED SAMPLING =====\n",
    "    use_length_balanced_sampling = True\n",
    "    length_bins = [(0, 200), (200, 350), (350, 512)]  # Short, medium, long documents \n",
    "    \n",
    "    # ===== MoE AUXILIARY LOSS =====\n",
    "    aux_loss_weight_start = 0.0001  # Conservative start\n",
    "    aux_loss_weight_end = 0.002  # Optimal low aux loss weight\n",
    "    aux_loss_warmup_steps = 1000  # Longer warmup for stability\n",
    "    \n",
    "    # ===== LANGUAGE-BALANCED LOSS =====\n",
    "    language_loss_weights = {\n",
    "        \"en\": 1.0,\n",
    "        \"hi\": 2.0,  \n",
    "        \"pa\": 2.0   \n",
    "    }\n",
    "    \n",
    "    # ===== GRADIENT CONTROL (OPTIMIZED) =====\n",
    "    gradient_clip_val = 0.5  # Optimal gradient clipping  \n",
    "    \n",
    "    # ===== GENERATION SETTINGS =====\n",
    "    num_beams = 5\n",
    "    generation_max_length = 128\n",
    "    generation_min_length = 30\n",
    "    \n",
    "    # ===== LOGGING & VALIDATION =====\n",
    "    LOG_INTERVALS = 500\n",
    "    VALIDATION_INTERVALS = 999999\n",
    "    validation_subset_size = 300\n",
    "    max_val_generation_batches = 50\n",
    "    num_workers = 6\n",
    "    \n",
    "    # ===== DATASET SIZES =====\n",
    "    train_size = None\n",
    "    val_size = None\n",
    "    test_size = None\n",
    "    \n",
    "    # ===== DATA AUGMENTATION =====\n",
    "    augment_low_resource = True\n",
    "    augmentation_factor = 2.0\n",
    "    augmentation_methods = ['back_translation', 'paraphrase', 'synonym']\n",
    "    \n",
    "    # ===== CHECKPOINTING =====\n",
    "    checkpoint_dir = \"./checkpoints\"\n",
    "    save_every_n_epochs = 1\n",
    "    save_best_only = True\n",
    "    best_metric = \"rougeL\"\n",
    "    patience = 5\n",
    "    min_delta = 0.0001\n",
    "    log_grad_norms = False\n",
    "    grad_norm_log_interval = 100\n",
    "    \n",
    "    def validate(self):\n",
    "        assert self.top_k <= self.num_experts\n",
    "        assert self.capacity_factor >= 1.0\n",
    "        assert len(self.languages) <= self.num_experts\n",
    "        assert self.batch_size > 0\n",
    "        assert self.learning_rate > 0\n",
    "        \n",
    "        if self.train_size is not None:\n",
    "            assert self.train_size > 0\n",
    "        if self.val_size is not None:\n",
    "            assert self.val_size > 0\n",
    "        if self.test_size is not None:\n",
    "            assert self.test_size > 0\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"CONFIGURATION FOR FULL DATASET TRAINING\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Model: {self.model_name}\")\n",
    "        print(f\"Languages: {', '.join(self.languages)}\")\n",
    "        print(f\"Optimizer: {self.optimizer.upper()}\")\n",
    "        print(f\"Experts: {self.num_experts} (top-{self.top_k})\")\n",
    "        print(f\"Batch size: {self.batch_size}\")\n",
    "        print(f\"Gradient accumulation: {self.gradient_accumulation_steps}\")\n",
    "        print(f\"Effective batch size: {self.batch_size * self.gradient_accumulation_steps}\")\n",
    "        print(f\"Learning rate: {self.learning_rate}\")\n",
    "        print(f\"Epochs: {self.num_epochs}\")\n",
    "        print(f\"Warmup steps: {self.warmup_steps}\")\n",
    "\n",
    "        print(f\"Dataset: FULL (train_size={self.train_size}, val_size={self.val_size}, test_size={self.test_size})\")\n",
    "        print(f\"Checkpoint dir: {self.checkpoint_dir}\")\n",
    "        print(f\"Early stopping patience: {self.patience}\")\n",
    "        print(\"=\" * 60)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d1539c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION FOR FULL DATASET TRAINING\n",
      "============================================================\n",
      "Model: google/mt5-small\n",
      "Languages: english, hindi, punjabi\n",
      "Optimizer: MUON\n",
      "Experts: 6 (top-2)\n",
      "Batch size: 16\n",
      "Gradient accumulation: 4\n",
      "Effective batch size: 64\n",
      "Learning rate: 0.03\n",
      "Epochs: 10\n",
      "Warmup steps: 2000\n",
      "Dataset: FULL (train_size=None, val_size=None, test_size=None)\n",
      "Checkpoint dir: ./checkpoints\n",
      "Early stopping patience: 5\n",
      "============================================================\n",
      "\n",
      "âœ“ Device: cuda\n",
      "âœ“ GPU: NVIDIA H100 80GB HBM3 MIG 3g.40gb\n",
      "âœ“ GPU Memory: 39.38 GB\n",
      "âœ“ Checkpoints: ./checkpoints/moe_xlsum_20251116_132710\n",
      "âœ“ Dataset mode: FULL\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config.validate()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create checkpoint directory with timestamp\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "config.checkpoint_dir = f\"./checkpoints/moe_xlsum_{timestamp}\"\n",
    "os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nâœ“ Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"âœ“ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "print(f\"âœ“ Checkpoints: {config.checkpoint_dir}\")\n",
    "print(f\"âœ“ Dataset mode: {'FULL' if config.train_size is None else f'SUBSET ({config.train_size} samples)'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f4d03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpoint:\n",
    "    def __init__(\n",
    "        self,\n",
    "        checkpoint_dir,\n",
    "        save_best_only=True,\n",
    "        best_metric=\"rouge1\",\n",
    "        patience=None,\n",
    "        min_delta=0.001,\n",
    "    ):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_metric = best_metric\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "\n",
    "        self.best_score = float(\"-inf\")\n",
    "        self.best_epoch = 0\n",
    "        self.patience_counter = 0\n",
    "        self.should_stop = False\n",
    "\n",
    "        self.best_model_dir = os.path.join(checkpoint_dir, \"best_model\")\n",
    "        self.epoch_checkpoints_dir = os.path.join(\n",
    "            checkpoint_dir, \"epoch_checkpoints\")\n",
    "\n",
    "        os.makedirs(self.best_model_dir, exist_ok=True)\n",
    "        os.makedirs(self.epoch_checkpoints_dir, exist_ok=True)\n",
    "\n",
    "    def save_checkpoint(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        epoch,\n",
    "        train_loss,\n",
    "        val_loss,\n",
    "        rouge_scores,\n",
    "        training_history,\n",
    "    ):\n",
    "        checkpoint_data = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"rouge_scores\": rouge_scores,\n",
    "            \"training_history\": training_history,\n",
    "            \"config\": config.__dict__,\n",
    "            \"best_score\": self.best_score,\n",
    "            \"best_epoch\": self.best_epoch,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        # Save epoch-specific checkpoint if not save_best_only\n",
    "        if not self.save_best_only:\n",
    "            epoch_path = os.path.join(\n",
    "                self.epoch_checkpoints_dir, f\"checkpoint_epoch_{epoch}.pt\"\n",
    "            )\n",
    "            torch.save(checkpoint_data, epoch_path)\n",
    "            print(f\"Saved epoch checkpoint to {epoch_path}\")\n",
    "\n",
    "        # Check if this is the best model\n",
    "        current_score = rouge_scores[self.best_metric]\n",
    "        if current_score > self.best_score + self.min_delta:\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            self.patience_counter = 0\n",
    "\n",
    "            # Save best model\n",
    "            best_path = os.path.join(self.best_model_dir, \"best_model.pt\")\n",
    "            torch.save(checkpoint_data, best_path)\n",
    "            print(\n",
    "                f\"New best model saved! {self.best_metric}: {current_score:.4f} (epoch {epoch})\"\n",
    "            )\n",
    "\n",
    "            model_to_save = model.module if hasattr(model, \"module\") else model\n",
    "            model_to_save.base_model.save_pretrained(\n",
    "                os.path.join(self.best_model_dir, \"hf_model\")\n",
    "            )\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "            print(f\"No improvement. Patience: {self.patience_counter}/{self.patience}\")\n",
    "\n",
    "        if self.patience and self.patience_counter >= self.patience:\n",
    "            self.should_stop = True\n",
    "            print(\n",
    "                f\"Early stopping triggered after {self.patience} epochs without improvement\"\n",
    "            )\n",
    "\n",
    "        metadata = {\n",
    "            \"best_score\": self.best_score,\n",
    "            \"best_epoch\": self.best_epoch,\n",
    "            \"current_epoch\": epoch,\n",
    "            \"patience_counter\": self.patience_counter,\n",
    "            \"training_complete\": False,\n",
    "        }\n",
    "\n",
    "        with open(\n",
    "            os.path.join(self.checkpoint_dir, \"training_metadata.json\"), \"w\"\n",
    "        ) as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path, model, optimizer=None, scheduler=None):\n",
    "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "\n",
    "        checkpoint = torch.load(\n",
    "            checkpoint_path, map_location=device\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "        if optimizer and \"optimizer_state_dict\" in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "        if scheduler and \"scheduler_state_dict\" in checkpoint:\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "\n",
    "        self.best_score = checkpoint.get(\"best_score\", float(\"-inf\"))\n",
    "        self.best_epoch = checkpoint.get(\"best_epoch\", 0)\n",
    "\n",
    "        print(f\"Checkpoint loaded successfully!\")\n",
    "        print(f\"Resuming from epoch {checkpoint['epoch']}\")\n",
    "        print(\n",
    "            f\"Best {self.best_metric} score so far: {self.best_score:.4f} (epoch {self.best_epoch})\"\n",
    "        )\n",
    "\n",
    "        return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df05f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoELayer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_experts, top_k, capacity_factor, language_codes=None, expert_dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_experts = num_experts\n",
    "        self.top_k = top_k\n",
    "        self.capacity_factor = capacity_factor\n",
    "        self.expert_dropout = expert_dropout\n",
    "\n",
    "        # Gating network with Layer Normalization for stability (SOTA practice)\n",
    "        self.gate_norm = nn.LayerNorm(hidden_size)\n",
    "        self.gate = nn.Linear(hidden_size, num_experts, bias=True)\n",
    "        # Initialize gate with smaller weights for numerical stability\n",
    "        nn.init.normal_(self.gate.weight, mean=0.0, std=0.01)\n",
    "        nn.init.zeros_(self.gate.bias)\n",
    "\n",
    "        # Expert networks (FFN layers) with careful initialization\n",
    "        self.experts = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(hidden_size, hidden_size * 4),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(hidden_size * 4, hidden_size),\n",
    "                )\n",
    "                for _ in range(num_experts)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Initialize expert weights with smaller std for stability\n",
    "        for expert in self.experts:\n",
    "            for module in expert:\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "                    if module.bias is not None:\n",
    "                        nn.init.zeros_(module.bias)\n",
    "\n",
    "        # Dynamic language expert mapping based on config\n",
    "        self.language_expert_map = {}\n",
    "        if language_codes is None:\n",
    "            language_codes = [\"en\", \"hi\", \"pa\"]\n",
    "        \n",
    "        # Map first N experts to languages, rest are shared\n",
    "        num_lang_experts = min(num_experts // 2, len(language_codes))\n",
    "        for i, lang_code in enumerate(language_codes[:num_lang_experts]):\n",
    "            self.language_expert_map[lang_code] = i\n",
    "        \n",
    "        # Remaining experts are shared\n",
    "        shared_experts = list(range(num_lang_experts, num_experts))\n",
    "        if shared_experts:\n",
    "            self.language_expert_map[\"shared\"] = shared_experts\n",
    "        \n",
    "        # Track overflow and routing statistics\n",
    "        self.overflow_count = 0\n",
    "        self.total_forward_calls = 0\n",
    "        self.register_buffer('expert_usage_count', torch.zeros(num_experts))\n",
    "\n",
    "    def forward(self, x, language_ids=None):\n",
    "        batch_size, seq_len, hidden_size = x.shape\n",
    "        x_flat = x.view(-1, hidden_size)  # [batch_size * seq_len, hidden_size]\n",
    "        num_tokens = x_flat.size(0)\n",
    "\n",
    "        # Apply LayerNorm before gating for numerical stability\n",
    "        x_flat_normed = self.gate_norm(x_flat)\n",
    "        \n",
    "        # Gating with optional language-aware biasing\n",
    "        gate_logits = self.gate(x_flat_normed)  # [num_tokens, num_experts]\n",
    "        \n",
    "        # Language-aware routing with ENHANCED bias for low-resource languages\n",
    "        if language_ids is not None and self.training:\n",
    "            lang_bias = torch.zeros_like(gate_logits)\n",
    "            \n",
    "            # Define language-specific bias strengths\n",
    "            lang_bias_strength = {\n",
    "                \"en\": 0.5,  # Standard bias for English\n",
    "                \"hi\": 1.2,  # Stronger bias for Hindi\n",
    "                \"pa\": 1.2   # Stronger bias for Punjabi\n",
    "            }\n",
    "            \n",
    "            for batch_idx, lang_id in enumerate(language_ids):\n",
    "                start_idx = batch_idx * seq_len\n",
    "                end_idx = start_idx + seq_len\n",
    "                \n",
    "                if lang_id in self.language_expert_map:\n",
    "                    expert_idx = self.language_expert_map[lang_id]\n",
    "                    bias_strength = lang_bias_strength.get(lang_id, 0.5)\n",
    "                    \n",
    "                    if isinstance(expert_idx, list):\n",
    "                        # Boost for shared experts\n",
    "                        for idx in expert_idx:\n",
    "                            lang_bias[start_idx:end_idx, idx] = 0.3\n",
    "                    else:\n",
    "                        # Strong boost for language-specific expert\n",
    "                        lang_bias[start_idx:end_idx, expert_idx] = bias_strength\n",
    "            \n",
    "            gate_logits = gate_logits + lang_bias\n",
    "        \n",
    "        gate_probs = F.softmax(gate_logits, dim=-1)  # [num_tokens, num_experts]\n",
    "\n",
    "        # Top-k gating - vectorized\n",
    "        top_k_probs, top_k_indices = torch.topk(gate_probs, self.top_k, dim=-1)\n",
    "        top_k_probs = top_k_probs / (top_k_probs.sum(dim=-1, keepdim=True) + 1e-8) \n",
    "\n",
    "        capacity = int(self.capacity_factor * num_tokens / self.num_experts)\n",
    "\n",
    "        expert_outputs = torch.zeros_like(x_flat)\n",
    "        expert_usage = torch.zeros(self.num_experts, device=x.device)\n",
    "\n",
    "        # Track expert usage for load balancing loss\n",
    "        for i in range(self.num_experts):\n",
    "            expert_mask = (top_k_indices == i).any(dim=-1)\n",
    "            expert_usage[i] = expert_mask.float().sum()\n",
    "        \n",
    "        if self.training:\n",
    "            self.expert_usage_count += expert_usage.detach()\n",
    "\n",
    "        active_experts = torch.unique(top_k_indices)\n",
    "        \n",
    "        for expert_idx in active_experts:\n",
    "            expert_mask = (top_k_indices == expert_idx).any(dim=-1)\n",
    "            \n",
    "            if not expert_mask.any():\n",
    "                continue\n",
    "            \n",
    "            token_indices = torch.where(expert_mask)[0]\n",
    "            expert_input = x_flat[expert_mask]\n",
    "            \n",
    "            # Calculate weights for this expert\n",
    "            expert_weights = torch.zeros(expert_input.size(0), device=x.device, dtype=x_flat.dtype)\n",
    "            for k_idx in range(self.top_k):\n",
    "                matches = (top_k_indices[token_indices, k_idx] == expert_idx)\n",
    "                expert_weights[matches] += top_k_probs[token_indices[matches], k_idx]\n",
    "            \n",
    "            # Handle capacity overflow with importance sampling\n",
    "            if expert_input.size(0) > capacity:\n",
    "                overflow_tokens = expert_input.size(0) - capacity\n",
    "                self.overflow_count += overflow_tokens\n",
    "                \n",
    "                _, top_indices = torch.topk(expert_weights, k=capacity, largest=True)\n",
    "                token_indices = token_indices[top_indices]\n",
    "                expert_input = expert_input[top_indices]\n",
    "                expert_weights = expert_weights[top_indices]\n",
    "            \n",
    "            expert_output = self.experts[expert_idx](expert_input)\n",
    "            \n",
    "            if self.training and self.expert_dropout > 0:\n",
    "                dropout_mask = torch.bernoulli(torch.full_like(expert_weights, 1 - self.expert_dropout))\n",
    "                expert_weights = expert_weights * dropout_mask / (1 - self.expert_dropout + 1e-8)\n",
    "            \n",
    "            expert_outputs[token_indices] += expert_output * expert_weights.unsqueeze(1)\n",
    "        \n",
    "        self.total_forward_calls += num_tokens\n",
    "        \n",
    "        # Load balancing auxiliary loss\n",
    "        expert_freq = expert_usage / (num_tokens + 1e-8)\n",
    "        expert_prob_avg = gate_probs.mean(dim=0)\n",
    "        aux_loss = self.num_experts * torch.sum(expert_freq * expert_prob_avg)\n",
    "\n",
    "        expert_outputs = expert_outputs.view(batch_size, seq_len, hidden_size)\n",
    "        return expert_outputs, aux_loss, expert_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23abc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MT5WithMoE(nn.Module):\n",
    "    def __init__(self, base_model, num_experts, top_k, capacity_factor, language_codes=None, expert_dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.config = base_model.config\n",
    "        self.current_language_ids = None\n",
    "        self.language_codes = language_codes\n",
    "        self.expert_dropout = expert_dropout\n",
    "\n",
    "        self._replace_ffn_with_moe(num_experts, top_k, capacity_factor)\n",
    "\n",
    "    def _replace_ffn_with_moe(self, num_experts, top_k, capacity_factor):\n",
    "        hidden_size = self.config.d_model\n",
    "\n",
    "        for layer in self.base_model.encoder.block:\n",
    "            if hasattr(layer.layer[1], \"DenseReluDense\"):\n",
    "                moe_layer_instance = MoELayer(\n",
    "                    hidden_size, num_experts, top_k, capacity_factor, \n",
    "                    self.language_codes, self.expert_dropout\n",
    "                )\n",
    "                layer.layer[1].DenseReluDense = MoEWrapper(moe_layer_instance, self)\n",
    "\n",
    "        for layer in self.base_model.decoder.block:\n",
    "            if hasattr(layer.layer[2], \"DenseReluDense\"):\n",
    "                moe_layer_instance = MoELayer(\n",
    "                    hidden_size, num_experts, top_k, capacity_factor, \n",
    "                    self.language_codes, self.expert_dropout\n",
    "                )\n",
    "                layer.layer[2].DenseReluDense = MoEWrapper(moe_layer_instance, self)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, language_ids=None, aux_loss_weight=None, language_loss_weights=None):\n",
    "        self.current_language_ids = language_ids\n",
    "        \n",
    "        aux_losses = []\n",
    "        expert_usage_stats = defaultdict(list)\n",
    "        hooks = []\n",
    "\n",
    "        def hook_fn(module, input, output):\n",
    "            if isinstance(module, MoELayer):\n",
    "                _, aux_loss, expert_usage = output\n",
    "                aux_losses.append(aux_loss.to(input_ids.device))\n",
    "                expert_usage_stats[id(module)].append(expert_usage)\n",
    "\n",
    "        try:\n",
    "            for module in self.modules():\n",
    "                if isinstance(module, MoELayer):\n",
    "                    hook = module.register_forward_hook(hook_fn)\n",
    "                    hooks.append(hook)\n",
    "\n",
    "            outputs = self.base_model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "            )\n",
    "\n",
    "            # Apply language-balanced loss weighting\n",
    "            if hasattr(outputs, \"loss\") and outputs.loss is not None and language_ids is not None and language_loss_weights is not None:\n",
    "                # Calculate per-sample loss weights based on language\n",
    "                batch_weights = torch.tensor(\n",
    "                    [language_loss_weights.get(lang, 1.0) for lang in language_ids],\n",
    "                    device=outputs.loss.device,\n",
    "                    dtype=outputs.loss.dtype\n",
    "                )\n",
    "                \n",
    "                # Apply weighted loss (mean of weighted per-sample losses)\n",
    "                weighted_loss = outputs.loss * batch_weights.mean()\n",
    "                outputs.loss = weighted_loss\n",
    "\n",
    "            if aux_losses:\n",
    "                total_aux_loss = sum(aux_losses) / len(aux_losses)\n",
    "                if hasattr(outputs, \"loss\") and outputs.loss is not None:\n",
    "                    # Use provided aux_loss_weight or fall back to config\n",
    "                    weight = aux_loss_weight if aux_loss_weight is not None else config.aux_loss_weight_end\n",
    "                    outputs.loss += weight * total_aux_loss\n",
    "\n",
    "        finally:\n",
    "            for hook in hooks:\n",
    "                hook.remove()\n",
    "            self.current_language_ids = None\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df054ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoEWrapper(nn.Module):\n",
    "    def __init__(self, moe_layer, parent_model):\n",
    "        super().__init__()\n",
    "        self.moe_layer = moe_layer\n",
    "        import weakref\n",
    "        self._parent_model = weakref.ref(parent_model)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        parent = self._parent_model()\n",
    "        language_ids = parent.current_language_ids if parent else None\n",
    "        output_tensor, aux_loss, expert_usage = self.moe_layer(x, language_ids=language_ids)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66f18a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualSummarizationDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data, max_input_length, max_target_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_input_length = max_input_length\n",
    "        self.max_target_length = max_target_length\n",
    "        self.lang_map = {\"english\": \"en\", \"hindi\": \"hi\", \"punjabi\": \"pa\"}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        full_lang = item['id'].split('.')[0]\n",
    "        lang_code = self.lang_map.get(full_lang, full_lang[:2])\n",
    "        lang_token = f\"<{lang_code}>\"\n",
    "        \n",
    "        input_text = f\"{lang_token} summarize: {item['text']}\"\n",
    "        target_text = item[\"target\"]\n",
    "\n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_input_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        target_encoding = self.tokenizer(\n",
    "            target_text,\n",
    "            max_length=self.max_target_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_encoding.input_ids.squeeze(),\n",
    "            \"attention_mask\": input_encoding.attention_mask.squeeze(),\n",
    "            \"labels\": target_encoding.input_ids.squeeze(),\n",
    "            \"language\": lang_code,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f38fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LengthBalancedSampler(torch.utils.data.Sampler):\n",
    "    \"\"\"Sampler that creates balanced batches across different document lengths\"\"\"\n",
    "    def __init__(self, dataset, batch_size, length_bins):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.length_bins = length_bins\n",
    "        \n",
    "        # Categorize samples by length\n",
    "        self.length_indices = {i: [] for i in range(len(length_bins))}\n",
    "        for idx, item in enumerate(dataset.data):\n",
    "            doc_len = len(item['text'].split())\n",
    "            for bin_idx, (min_len, max_len) in enumerate(length_bins):\n",
    "                if min_len <= doc_len < max_len:\n",
    "                    self.length_indices[bin_idx].append(idx)\n",
    "                    break\n",
    "        \n",
    "        # Calculate total batches\n",
    "        self.total_samples = len(dataset)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        indices = []\n",
    "        # Sample from each bin proportionally\n",
    "        for bin_idx in range(len(self.length_bins)):\n",
    "            bin_indices = self.length_indices[bin_idx].copy()\n",
    "            np.random.shuffle(bin_indices)\n",
    "            indices.extend(bin_indices)\n",
    "        \n",
    "        np.random.shuffle(indices)\n",
    "        return iter(indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "def create_curriculum_datasets(train_data, val_data, phase_config):\n",
    "    \"\"\"Filter datasets based on curriculum phase constraints\"\"\"\n",
    "    max_input_len = phase_config['max_input_len']\n",
    "    max_target_len = phase_config['max_target_len']\n",
    "    \n",
    "    filtered_train = []\n",
    "    for item in train_data:\n",
    "        input_len = len(item['text'].split())\n",
    "        target_len = len(item['target'].split())\n",
    "        if input_len <= max_input_len and target_len <= max_target_len:\n",
    "            filtered_train.append(item)\n",
    "    \n",
    "    # Don't filter validation data\n",
    "    return filtered_train, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07361a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_text_simple(text, summary, lang_code, method='synonym'):\n",
    "    \"\"\"Simple augmentation by adding variation to the text.\"\"\"\n",
    "    import random\n",
    "    \n",
    "    # Method 1: Add contextual prefix\n",
    "    if method == 'paraphrase':\n",
    "        prefixes = [\"à¤¯à¤¹ à¤¹à¥ˆ: \", \"à¤¸à¤®à¤¾à¤šà¤¾à¤°: \", \"à¤°à¤¿à¤ªà¥‹à¤°à¥à¤Ÿ: \"] if lang_code == 'hi' else [\"à¨‡à¨¹ à¨¹à©ˆ: \", \"à¨–à¨¼à¨¬à¨°: \", \"à¨°à¨¿à¨ªà©‹à¨°à¨Ÿ: \"]\n",
    "        augmented_text = random.choice(prefixes) + text\n",
    "        return augmented_text, summary\n",
    "    \n",
    "    # Method 2: Simple word reordering for first sentence\n",
    "    elif method == 'synonym':\n",
    "        # Keep original for now (can be enhanced with actual synonym replacement)\n",
    "        return text, summary\n",
    "    \n",
    "    # Method 3: Back-translation simulation (shuffle middle sentences)\n",
    "    elif method == 'back_translation':\n",
    "        sentences = text.split('à¥¤') if lang_code == 'hi' else text.split('à¥¤')\n",
    "        if len(sentences) > 3:\n",
    "            # Keep first and last, shuffle middle\n",
    "            middle = sentences[1:-1]\n",
    "            random.shuffle(middle)\n",
    "            augmented_text = sentences[0] + 'à¥¤' + 'à¥¤'.join(middle) + 'à¥¤' + sentences[-1]\n",
    "            return augmented_text, summary\n",
    "    \n",
    "    return text, summary\n",
    "\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    test_data = []\n",
    "\n",
    "    DATASET_NAME = \"csebuetnlp/xlsum\"\n",
    "    \n",
    "    # First pass: collect all language data to determine English count\n",
    "    lang_train_items = {}\n",
    "    \n",
    "    for lang in config.languages:\n",
    "        print(f\"Loading {lang} data...\")\n",
    "\n",
    "        # Load training data\n",
    "        if config.train_size is None:\n",
    "            train_split = load_dataset(DATASET_NAME, lang, split=\"train\")\n",
    "        else:\n",
    "            train_per_lang = config.train_size // len(config.languages)\n",
    "            train_split = load_dataset(DATASET_NAME, lang, split=f\"train[:{train_per_lang}]\")\n",
    "        \n",
    "        train_items = []\n",
    "        for item in train_split:\n",
    "            train_items.append({\n",
    "                \"text\": item[\"text\"],\n",
    "                \"target\": item[\"summary\"],\n",
    "                \"id\": f\"{lang}.{len(train_items)}\",\n",
    "            })\n",
    "        \n",
    "        lang_train_items[lang] = train_items\n",
    "        print(f\"  Loaded {len(train_items)} samples\")\n",
    "    \n",
    "    # Get English count as target\n",
    "    english_count = len(lang_train_items['english'])\n",
    "    print(f\"\\nðŸŽ¯ Target count (matching English): {english_count} samples per language\")\n",
    "    \n",
    "    # Second pass: augment Hindi and Punjabi to match English\n",
    "    for lang in config.languages:\n",
    "        train_items = lang_train_items[lang]\n",
    "        \n",
    "        # Augment low-resource languages to match English count\n",
    "        if config.augment_low_resource and lang in ['hindi', 'punjabi']:\n",
    "            lang_code = 'hi' if lang == 'hindi' else 'pa'\n",
    "            original_count = len(train_items)\n",
    "            target_count = english_count  # Match English count\n",
    "            augmented_items = []\n",
    "            \n",
    "            import random\n",
    "            methods = config.augmentation_methods\n",
    "            \n",
    "            print(f\"\\n  Augmenting {lang} from {original_count} to {target_count} samples...\")\n",
    "            \n",
    "            while len(train_items) + len(augmented_items) < target_count:\n",
    "                # Randomly select an item to augment\n",
    "                item = random.choice(train_items)\n",
    "                method = random.choice(methods)\n",
    "                \n",
    "                aug_text, aug_summary = augment_text_simple(\n",
    "                    item['text'], item['target'], lang_code, method\n",
    "                )\n",
    "                \n",
    "                augmented_items.append({\n",
    "                    \"text\": aug_text,\n",
    "                    \"target\": aug_summary,\n",
    "                    \"id\": f\"{lang}.aug_{len(augmented_items)}\",\n",
    "                })\n",
    "            \n",
    "            train_items.extend(augmented_items)\n",
    "            print(f\"  âœ“ {lang} augmented: +{len(augmented_items)} samples (total: {len(train_items)})\")\n",
    "            print(f\"  âœ“ Balance ratio: {len(train_items)/english_count:.2f}x relative to English\")\n",
    "\n",
    "        # Load validation data\n",
    "        if config.val_size is None:\n",
    "            val_split = load_dataset(DATASET_NAME, lang, split=\"validation\")\n",
    "        else:\n",
    "            val_per_lang = config.val_size // len(config.languages)\n",
    "            val_split = load_dataset(DATASET_NAME, lang, split=f\"validation[:{val_per_lang}]\")\n",
    "        \n",
    "        val_items = []\n",
    "        for item in val_split:\n",
    "            val_items.append({\n",
    "                \"text\": item[\"text\"],\n",
    "                \"target\": item[\"summary\"],\n",
    "                \"id\": f\"{lang}.{len(val_items)}\",\n",
    "            })\n",
    "\n",
    "        # Load test data\n",
    "        if config.test_size is None:\n",
    "            test_split = load_dataset(DATASET_NAME, lang, split=\"test\")\n",
    "        else:\n",
    "            test_per_lang = config.test_size // len(config.languages)\n",
    "            test_split = load_dataset(DATASET_NAME, lang, split=f\"test[:{test_per_lang}]\")\n",
    "        \n",
    "        test_items = []\n",
    "        for item in test_split:\n",
    "            test_items.append({\n",
    "                \"text\": item[\"text\"],\n",
    "                \"target\": item[\"summary\"],\n",
    "                \"id\": f\"{lang}.{len(test_items)}\",\n",
    "            })\n",
    "\n",
    "        train_data.extend(train_items)\n",
    "        val_data.extend(val_items)\n",
    "        test_data.extend(test_items)\n",
    "\n",
    "        print(f\"âœ“ {lang} - Train: {len(train_items)}, Val: {len(val_items)}, Test: {len(test_items)}\")\n",
    "\n",
    "    # Shuffle datasets\n",
    "    np.random.shuffle(train_data)\n",
    "    np.random.shuffle(val_data)\n",
    "    np.random.shuffle(test_data)\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TOTAL DATASET SIZES (BALANCED)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Train: {len(train_data):,} samples\")\n",
    "    print(f\"Val:   {len(val_data):,} samples\")\n",
    "    print(f\"Test:  {len(test_data):,} samples\")\n",
    "    \n",
    "    # Calculate and display per-language distribution\n",
    "    train_lang_counts = {'english': 0, 'hindi': 0, 'punjabi': 0}\n",
    "    for item in train_data:\n",
    "        lang = item['id'].split('.')[0]\n",
    "        if lang in train_lang_counts:\n",
    "            train_lang_counts[lang] += 1\n",
    "    \n",
    "    print(f\"\\nTraining Data Distribution:\")\n",
    "    for lang, count in train_lang_counts.items():\n",
    "        percentage = (count / len(train_data)) * 100\n",
    "        print(f\"  {lang.capitalize()}: {count:,} ({percentage:.1f}%)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ada54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge_scores(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(\n",
    "        [\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "\n",
    "    rouge1_scores = []\n",
    "    rouge2_scores = []\n",
    "    rougeL_scores = []\n",
    "\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        scores = scorer.score(ref, pred)\n",
    "        rouge1_scores.append(scores[\"rouge1\"].fmeasure)\n",
    "        rouge2_scores.append(scores[\"rouge2\"].fmeasure)\n",
    "        rougeL_scores.append(scores[\"rougeL\"].fmeasure)\n",
    "\n",
    "    return {\n",
    "        \"rouge1\": np.mean(rouge1_scores),\n",
    "        \"rouge2\": np.mean(rouge2_scores),\n",
    "        \"rougeL\": np.mean(rougeL_scores),\n",
    "    }\n",
    "\n",
    "def calculate_bleu_score(predictions, references):\n",
    "    \"\"\"Calculate BLEU score using sacrebleu\"\"\"\n",
    "    # sacrebleu expects references as list of lists\n",
    "    refs_formatted = [[ref] for ref in references]\n",
    "    bleu = corpus_bleu(predictions, refs_formatted)\n",
    "    return bleu.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec89a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_decode(model, input_ids, attention_mask, labels, tokenizer, languages=None):\n",
    "    try:\n",
    "        model_to_generate = model.module if hasattr(model, \"module\") else model\n",
    "        \n",
    "        generated_ids = model_to_generate.base_model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=config.generation_max_length,\n",
    "            min_length=config.generation_min_length,\n",
    "            num_beams=config.num_beams,\n",
    "            length_penalty=2.0,\n",
    "            repetition_penalty=2.5,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3,\n",
    "            forced_bos_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "        \n",
    "        pred_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        \n",
    "        labels_copy = labels.clone()\n",
    "        labels_copy[labels_copy == -100] = tokenizer.pad_token_id\n",
    "        ref_texts = tokenizer.batch_decode(labels_copy, skip_special_tokens=True)\n",
    "        \n",
    "        # Filter out empty predictions\n",
    "        filtered_preds = []\n",
    "        filtered_refs = []\n",
    "        for pred, ref in zip(pred_texts, ref_texts):\n",
    "            if pred.strip():  # Only include non-empty predictions\n",
    "                filtered_preds.append(pred.strip())\n",
    "                filtered_refs.append(ref.strip())\n",
    "        \n",
    "        return filtered_preds if filtered_preds else pred_texts, ref_texts\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Generation failed: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def validate(model, val_loader, tokenizer, use_subset=False, subset_size=None):\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    val_predictions = []\n",
    "    val_references = []\n",
    "    batches_processed = 0\n",
    "    \n",
    "    # Track per-language metrics\n",
    "    language_losses = {\"en\": [], \"hi\": [], \"pa\": []}\n",
    "    language_preds = {\"en\": {\"preds\": [], \"refs\": []}, \"hi\": {\"preds\": [], \"refs\": []}, \"pa\": {\"preds\": [], \"refs\": []}}\n",
    "    \n",
    "    batches_to_process = subset_size if use_subset and subset_size else len(val_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(val_loader):\n",
    "            if use_subset and batch_idx >= batches_to_process:\n",
    "                break\n",
    "            \n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            languages = batch[\"language\"]\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels,\n",
    "                    language_ids=languages,\n",
    "                    language_loss_weights=config.language_loss_weights\n",
    "                )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            if loss.dim() > 0:\n",
    "                loss = loss.mean()\n",
    "            val_loss += loss.item()\n",
    "            batches_processed += 1\n",
    "            \n",
    "            # Track per-language losses\n",
    "            for lang in languages:\n",
    "                if lang in language_losses:\n",
    "                    language_losses[lang].append(loss.item())\n",
    "\n",
    "            pred_texts, ref_texts = generate_and_decode(\n",
    "                model, input_ids, attention_mask, labels, tokenizer, languages\n",
    "            )\n",
    "            \n",
    "            if pred_texts is not None and pred_texts:\n",
    "                val_predictions.extend(pred_texts)\n",
    "                val_references.extend(ref_texts)\n",
    "                \n",
    "                # Track per-language predictions\n",
    "                for pred, ref, lang in zip(pred_texts, ref_texts, languages):\n",
    "                    if lang in language_preds:\n",
    "                        language_preds[lang][\"preds\"].append(pred)\n",
    "                        language_preds[lang][\"refs\"].append(ref)\n",
    "\n",
    "    avg_val_loss = val_loss / max(batches_processed, 1)\n",
    "    \n",
    "    # Calculate per-language losses\n",
    "    per_lang_losses = {}\n",
    "    for lang, losses in language_losses.items():\n",
    "        if losses:\n",
    "            per_lang_losses[lang] = np.mean(losses)\n",
    "    \n",
    "    # Calculate metrics if we have predictions\n",
    "    if val_predictions and any(p.strip() for p in val_predictions):\n",
    "        rouge_scores = calculate_rouge_scores(val_predictions, val_references)\n",
    "        bleu_score = calculate_bleu_score(val_predictions, val_references)\n",
    "        rouge_scores[\"bleu\"] = bleu_score\n",
    "    else:\n",
    "        rouge_scores = {\"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0, \"bleu\": 0.0}\n",
    "        print(\"Warning: No valid predictions generated for metric calculation\")\n",
    "    \n",
    "    # Calculate per-language ROUGE and BLEU\n",
    "    per_lang_rouge = {}\n",
    "    for lang, data in language_preds.items():\n",
    "        if data[\"preds\"]:\n",
    "            lang_rouge = calculate_rouge_scores(data[\"preds\"], data[\"refs\"])\n",
    "            lang_bleu = calculate_bleu_score(data[\"preds\"], data[\"refs\"])\n",
    "            lang_rouge[\"bleu\"] = lang_bleu\n",
    "            per_lang_rouge[lang] = lang_rouge\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    return avg_val_loss, rouge_scores, per_lang_losses, per_lang_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c810fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_curriculum(model, train_data, val_data, tokenizer, use_muon=True, lr=None):\n",
    "    \"\"\"\n",
    "    Train model using curriculum learning with 3 phases:\n",
    "    Phase 1: Short documents (easy)\n",
    "    Phase 2: Mixed lengths (medium)\n",
    "    Phase 3: Long documents (hard)\n",
    "    \"\"\"\n",
    "    if not config.use_curriculum:\n",
    "        # If curriculum learning disabled, use standard training\n",
    "        print(\"âš ï¸  Curriculum learning disabled. Using standard training...\")\n",
    "        train_dataset = MultilingualSummarizationDataset(\n",
    "            tokenizer, train_data, config.max_input_length, config.max_target_length\n",
    "        )\n",
    "        val_dataset = MultilingualSummarizationDataset(\n",
    "            tokenizer, val_data, config.max_input_length, config.max_target_length\n",
    "        )\n",
    "        \n",
    "        if config.use_length_balanced_sampling:\n",
    "            train_sampler = LengthBalancedSampler(train_dataset, config.batch_size, config.length_bins)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=config.batch_size, sampler=train_sampler,\n",
    "                                    num_workers=config.num_workers, pin_memory=True)\n",
    "        else:\n",
    "            train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True,\n",
    "                                    num_workers=config.num_workers, pin_memory=True)\n",
    "        \n",
    "        val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False,\n",
    "                              num_workers=config.num_workers, pin_memory=True)\n",
    "        \n",
    "        return train_model(model, train_loader, val_loader, tokenizer, use_muon=use_muon, lr=lr)\n",
    "    \n",
    "    # Curriculum Learning Implementation\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸŽ“ CURRICULUM LEARNING ENABLED\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    all_history = {\n",
    "        \"train_losses\": [],\n",
    "        \"val_losses\": [],\n",
    "        \"val_rouge_scores\": [],\n",
    "        \"phases\": []\n",
    "    }\n",
    "    \n",
    "    cumulative_epoch = 0\n",
    "    \n",
    "    for phase_idx, phase in enumerate(config.curriculum_phases):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ðŸ“š {phase['name']}\")\n",
    "        print(f\"   Max Input Length: {phase['max_input_len']}\")\n",
    "        print(f\"   Max Target Length: {phase['max_target_len']}\")\n",
    "        print(f\"   Epochs: {phase['epochs']}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        # Create phase-specific datasets\n",
    "        phase_train_data, phase_val_data = create_curriculum_datasets(train_data, val_data, phase)\n",
    "        \n",
    "        print(f\"Phase {phase_idx + 1} Data: {len(phase_train_data)} training samples\")\n",
    "        \n",
    "        train_dataset = MultilingualSummarizationDataset(\n",
    "            tokenizer, phase_train_data, phase['max_input_len'], phase['max_target_len']\n",
    "        )\n",
    "        val_dataset = MultilingualSummarizationDataset(\n",
    "            tokenizer, phase_val_data, phase['max_input_len'], phase['max_target_len']\n",
    "        )\n",
    "        \n",
    "        # Use length-balanced sampling if enabled\n",
    "        if config.use_length_balanced_sampling:\n",
    "            train_sampler = LengthBalancedSampler(train_dataset, config.batch_size, config.length_bins)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=config.batch_size, sampler=train_sampler,\n",
    "                                    num_workers=config.num_workers, pin_memory=True)\n",
    "        else:\n",
    "            train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True,\n",
    "                                    num_workers=config.num_workers, pin_memory=True)\n",
    "        \n",
    "        val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False,\n",
    "                              num_workers=config.num_workers, pin_memory=True)\n",
    "        \n",
    "        # Temporarily adjust config for this phase\n",
    "        original_epochs = config.num_epochs\n",
    "        config.num_epochs = phase['epochs']\n",
    "        \n",
    "        # Train for this phase\n",
    "        phase_history = train_model(model, train_loader, val_loader, tokenizer, use_muon=use_muon, lr=lr)\n",
    "        \n",
    "        # Restore original config\n",
    "        config.num_epochs = original_epochs\n",
    "        \n",
    "        # Aggregate history\n",
    "        all_history[\"train_losses\"].extend(phase_history[\"train_losses\"])\n",
    "        all_history[\"val_losses\"].extend(phase_history[\"val_losses\"])\n",
    "        all_history[\"val_rouge_scores\"].extend(phase_history[\"val_rouge_scores\"])\n",
    "        all_history[\"phases\"].append({\n",
    "            \"name\": phase['name'],\n",
    "            \"epochs\": phase['epochs'],\n",
    "            \"start_epoch\": cumulative_epoch,\n",
    "            \"end_epoch\": cumulative_epoch + phase['epochs']\n",
    "        })\n",
    "        \n",
    "        cumulative_epoch += phase['epochs']\n",
    "        \n",
    "        print(f\"\\nâœ… {phase['name']} completed!\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸŽ‰ CURRICULUM LEARNING COMPLETED\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Copy other history fields\n",
    "    all_history[\"training_time\"] = phase_history.get(\"training_time\", 0)\n",
    "    all_history[\"grad_norms\"] = phase_history.get(\"grad_norms\", [])\n",
    "    all_history[\"overflow_steps\"] = phase_history.get(\"overflow_steps\", [])\n",
    "    \n",
    "    return all_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efcbc5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, tokenizer, resume_from_checkpoint=None, use_muon=True, lr=None):\n",
    "    # Separate parameters for Muon (2D) and AdamW (1D)\n",
    "    if use_muon:\n",
    "        muon_params = []\n",
    "        adamw_params = []\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                # Use Muon for 2D+ parameters (except embeddings and final layer)\n",
    "                if param.ndim >= 2 and 'embed' not in name.lower() and 'lm_head' not in name.lower():\n",
    "                    muon_params.append(param)\n",
    "                else:\n",
    "                    adamw_params.append(param)\n",
    "        \n",
    "        # Use provided LR or default\n",
    "        muon_lr = lr if lr is not None else config.learning_rate\n",
    "        \n",
    "        # Use official SingleDeviceMuonWithAuxAdam for single-device training\n",
    "        from muon import SingleDeviceMuonWithAuxAdam\n",
    "        param_groups = [\n",
    "            dict(params=muon_params, use_muon=True, lr=muon_lr, momentum=0.95, weight_decay=config.weight_decay),\n",
    "            dict(params=adamw_params, use_muon=False, lr=muon_lr * 0.015, betas=(0.9, 0.95), eps=1e-10, weight_decay=config.weight_decay)\n",
    "        ]\n",
    "        optimizer = SingleDeviceMuonWithAuxAdam(param_groups)\n",
    "        \n",
    "        print(f\"\\nâœ“ Using Muon optimizer with LR={muon_lr:.2e}\")\n",
    "        print(f\"  - Muon params: {len(muon_params)} (2D+ weights)\")\n",
    "        print(f\"  - AdamW params: {len(adamw_params)} (embeddings, biases, norms)\\n\")\n",
    "    else:\n",
    "        optimizer = AdamW(\n",
    "            model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay\n",
    "        )\n",
    "        print(f\"\\nâœ“ Using AdamW optimizer with LR={config.learning_rate:.2e}\\n\")\n",
    "\n",
    "    total_steps = len(train_loader) * config.num_epochs // config.gradient_accumulation_steps\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=config.warmup_steps, num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # No AMP scaler - using full fp32 precision for MoE stability\n",
    "    print(\"\\nâš¡ Training in full FP32 precision (no AMP) for maximum stability\")\n",
    "\n",
    "    # Initialize checkpoint manager\n",
    "    checkpoint_manager = ModelCheckpoint(\n",
    "        checkpoint_dir=config.checkpoint_dir,\n",
    "        save_best_only=config.save_best_only,\n",
    "        best_metric=config.best_metric,\n",
    "        patience=config.patience,\n",
    "        min_delta=config.min_delta,\n",
    "    )\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_rouge_scores = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    if resume_from_checkpoint:\n",
    "        checkpoint = checkpoint_manager.load_checkpoint(\n",
    "            resume_from_checkpoint, model, optimizer, scheduler\n",
    "        )\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        train_losses = checkpoint[\"training_history\"][\"train_losses\"]\n",
    "        val_losses = checkpoint[\"training_history\"][\"val_losses\"]\n",
    "        val_rouge_scores = checkpoint[\"training_history\"][\"val_rouge_scores\"]\n",
    "\n",
    "    print(f\"\\nTraining: {config.num_epochs} epochs, {total_steps} steps, batch size {config.batch_size * config.gradient_accumulation_steps}\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    global_step = 0\n",
    "    \n",
    "    # Gradient monitoring\n",
    "    grad_norms = []\n",
    "    overflow_steps = []\n",
    "\n",
    "    for epoch in range(start_epoch, config.num_epochs):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Epoch {epoch+1}/{config.num_epochs}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        batches_processed = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            if batch_idx % 100 == 0 and batch_idx > 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "            \n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            languages = batch[\"language\"]\n",
    "\n",
    "            # Dynamic aux loss warmup (critical for MoE stability)\n",
    "            if global_step < config.aux_loss_warmup_steps:\n",
    "                # Linear warmup from start to end weight\n",
    "                progress = global_step / config.aux_loss_warmup_steps\n",
    "                current_aux_weight = (\n",
    "                    config.aux_loss_weight_start + \n",
    "                    progress * (config.aux_loss_weight_end - config.aux_loss_weight_start)\n",
    "                )\n",
    "            else:\n",
    "                current_aux_weight = config.aux_loss_weight_end\n",
    "\n",
    "            # Forward pass with language-balanced loss (FP32, no AMP)\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels,\n",
    "                language_ids=languages,\n",
    "                aux_loss_weight=current_aux_weight,  # Pass dynamic aux loss weight\n",
    "                language_loss_weights=config.language_loss_weights  # Pass language weights\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            if loss.dim() > 0:\n",
    "                loss = loss.mean()\n",
    "            \n",
    "            # Scale loss for gradient accumulation\n",
    "            loss = loss / config.gradient_accumulation_steps\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            if (batch_idx + 1) % config.gradient_accumulation_steps == 0:\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip_val)\n",
    "                \n",
    "                if config.log_grad_norms and global_step % config.grad_norm_log_interval == 0:\n",
    "                    grad_norms.append((global_step, grad_norm.item()))\n",
    "                \n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "                global_step += 1\n",
    "\n",
    "            epoch_loss += loss.item() * config.gradient_accumulation_steps\n",
    "            batches_processed += 1\n",
    "\n",
    "            # Intra-epoch validation\n",
    "            if global_step > 0 and global_step % config.VALIDATION_INTERVALS == 0:\n",
    "                subset_batches = config.validation_subset_size // config.batch_size\n",
    "                avg_val_loss, rouge_scores, per_lang_losses, per_lang_rouge = validate(\n",
    "                    model, val_loader, tokenizer, use_subset=True, subset_size=subset_batches\n",
    "                )\n",
    "                \n",
    "                # Log per-language metrics\n",
    "                print(f\"\\nPer-Language Losses: \", end=\"\")\n",
    "                for lang, loss in per_lang_losses.items():\n",
    "                    print(f\"{lang.upper()}={loss:.4f} \", end=\"\")\n",
    "                print()\n",
    "\n",
    "            # Log training progress\n",
    "            if global_step % config.LOG_INTERVALS == 0 and global_step > 0:\n",
    "                avg_recent_loss = epoch_loss / max(batches_processed, 1)\n",
    "                print(f\"Step {global_step} | Loss: {avg_recent_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "\n",
    "        # Calculate average training loss for the epoch\n",
    "        avg_train_loss = epoch_loss / max(batches_processed, 1)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        print(f\"\\nValidating epoch {epoch+1}...\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        model.eval()\n",
    "        eoe_val_loss = 0\n",
    "        eoe_val_predictions = []\n",
    "        eoe_val_references = []\n",
    "        eoe_batches_processed = 0\n",
    "        eoe_generation_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                languages = batch[\"language\"]\n",
    "\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels,\n",
    "                    language_ids=languages,\n",
    "                    aux_loss_weight=config.aux_loss_weight_end,  # Use final weight\n",
    "                    language_loss_weights=config.language_loss_weights\n",
    "                )\n",
    "\n",
    "                loss = outputs.loss\n",
    "                if loss.dim() > 0:\n",
    "                    loss = loss.mean()\n",
    "                eoe_val_loss += loss.item()\n",
    "                eoe_batches_processed += 1\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                # Generate predictions only for first few batches\n",
    "                if eoe_generation_batches < config.max_val_generation_batches:\n",
    "                    pred_texts, ref_texts = generate_and_decode(\n",
    "                        model, input_ids, attention_mask, labels, tokenizer, languages\n",
    "                    )\n",
    "                    \n",
    "                    if pred_texts is not None:\n",
    "                        eoe_val_predictions.extend(pred_texts)\n",
    "                        eoe_val_references.extend(ref_texts)\n",
    "                    eoe_generation_batches += 1\n",
    "\n",
    "        avg_eoe_val_loss = eoe_val_loss / max(eoe_batches_processed, 1)\n",
    "        val_losses.append(avg_eoe_val_loss)\n",
    "\n",
    "        # Calculate metrics including BLEU\n",
    "        if eoe_val_predictions:\n",
    "            eoe_rouge_scores = calculate_rouge_scores(eoe_val_predictions, eoe_val_references)\n",
    "            eoe_bleu_score = calculate_bleu_score(eoe_val_predictions, eoe_val_references)\n",
    "            eoe_rouge_scores[\"bleu\"] = eoe_bleu_score\n",
    "        else:\n",
    "            eoe_rouge_scores = {\"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0, \"bleu\": 0.0}\n",
    "        \n",
    "        val_rouge_scores.append(eoe_rouge_scores)\n",
    "        \n",
    "        # Calculate per-language metrics for end-of-epoch\n",
    "        eoe_per_lang_losses = {\"en\": [], \"hi\": [], \"pa\": []}\n",
    "        eoe_per_lang_preds = {\"en\": {\"preds\": [], \"refs\": []}, \"hi\": {\"preds\": [], \"refs\": []}, \"pa\": {\"preds\": [], \"refs\": []}}\n",
    "        eoe_val_references.extend(ref_texts)\n",
    "        for pred, ref, lang in zip(eoe_val_predictions, eoe_val_references, [\"en\", \"hi\", \"pa\"] * (len(eoe_val_predictions) // 3 + 1)):\n",
    "            if lang in eoe_per_lang_preds:\n",
    "                eoe_per_lang_preds[lang][\"preds\"].append(pred)\n",
    "                eoe_per_lang_preds[lang][\"refs\"].append(ref)\n",
    "        \n",
    "        eoe_per_lang_rouge = {}\n",
    "        for lang, data in eoe_per_lang_preds.items():\n",
    "            if data[\"preds\"]:\n",
    "                lang_rouge = calculate_rouge_scores(data[\"preds\"], data[\"refs\"])\n",
    "                lang_bleu = calculate_bleu_score(data[\"preds\"], data[\"refs\"])\n",
    "                lang_rouge[\"bleu\"] = lang_bleu\n",
    "                eoe_per_lang_rouge[lang] = lang_rouge\n",
    "\n",
    "        training_history = {\n",
    "            \"train_losses\": train_losses,\n",
    "            \"val_losses\": val_losses,\n",
    "            \"val_rouge_scores\": val_rouge_scores,\n",
    "            \"per_language_rouge\": eoe_per_lang_rouge if eoe_per_lang_rouge else {},\n",
    "            \"training_time\": time.time() - start_time,\n",
    "            \"grad_norms\": grad_norms,\n",
    "            \"overflow_steps\": overflow_steps,\n",
    "        }\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_eoe_val_loss:.4f}, R1={eoe_rouge_scores['rouge1']:.4f}, R2={eoe_rouge_scores['rouge2']:.4f}, RL={eoe_rouge_scores['rougeL']:.4f}, BLEU={eoe_rouge_scores.get('bleu', 0.0):.2f}, Time={(time.time() - start_time)/60:.1f}min\")\n",
    "        \n",
    "        # Display per-language scores\n",
    "        if eoe_per_lang_rouge:\n",
    "            print(f\"  Per-Language ROUGE-L / BLEU: \", end=\"\")\n",
    "            for lang, scores in eoe_per_lang_rouge.items():\n",
    "                print(f\"{lang.upper()}={scores['rougeL']:.4f}/{scores.get('bleu', 0.0):.2f} \", end=\"\")\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        # Report overflow statistics\n",
    "        if overflow_steps:\n",
    "            overflow_rate = len(overflow_steps) / max(global_step, 1) * 100\n",
    "            if overflow_rate > 5.0:\n",
    "                print(f\"  âš ï¸  High overflow rate: {overflow_rate:.1f}% ({len(overflow_steps)}/{global_step} steps)\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % config.save_every_n_epochs == 0:\n",
    "            checkpoint_manager.save_checkpoint(\n",
    "                model,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                epoch,\n",
    "                avg_train_loss,\n",
    "                avg_eoe_val_loss,\n",
    "                eoe_rouge_scores,\n",
    "                training_history,\n",
    "            )\n",
    "\n",
    "        # Check for early stopping\n",
    "        if checkpoint_manager.should_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Training complete\n",
    "    final_training_time = time.time() - start_time\n",
    "    training_history[\"training_time\"] = final_training_time\n",
    "    training_history[\"training_complete\"] = True\n",
    "\n",
    "    # Save final checkpoint\n",
    "    checkpoint_manager.save_checkpoint(\n",
    "        model,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        epoch,\n",
    "        avg_train_loss,\n",
    "        avg_eoe_val_loss,\n",
    "        eoe_rouge_scores,\n",
    "        training_history,\n",
    "    )\n",
    "\n",
    "    # Update metadata\n",
    "    metadata = {\n",
    "        \"best_score\": checkpoint_manager.best_score,\n",
    "        \"best_epoch\": checkpoint_manager.best_epoch,\n",
    "        \"final_epoch\": epoch,\n",
    "        \"training_complete\": True,\n",
    "        \"total_training_time\": final_training_time,\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(config.checkpoint_dir, \"training_metadata.json\"), \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    print(f\"\\nTraining completed! Best {config.best_metric}: {checkpoint_manager.best_score:.4f} at epoch {checkpoint_manager.best_epoch}\\n\")\n",
    "    \n",
    "    return training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b9763de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, tokenizer):\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_references = []\n",
    "    language_performance = {\"en\": {\"preds\": [], \"refs\": []}, \n",
    "                           \"hi\": {\"preds\": [], \"refs\": []}, \n",
    "                           \"pa\": {\"preds\": [], \"refs\": []}}\n",
    "    \n",
    "    print(\"Starting evaluation on test set...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            languages = batch[\"language\"]\n",
    "            \n",
    "            # Generate predictions with error handling\n",
    "            pred_texts, ref_texts = generate_and_decode(\n",
    "                model, input_ids, attention_mask, labels, tokenizer\n",
    "            )\n",
    "            \n",
    "            if pred_texts is None:\n",
    "                print(f\"[Warning] Skipping batch {batch_idx} due to generation error\")\n",
    "                continue\n",
    "            \n",
    "            all_predictions.extend(pred_texts)\n",
    "            all_references.extend(ref_texts)\n",
    "            \n",
    "            # Track per-language performance\n",
    "            for pred, ref, lang in zip(pred_texts, ref_texts, languages):\n",
    "                if lang in language_performance:\n",
    "                    language_performance[lang][\"preds\"].append(pred)\n",
    "                    language_performance[lang][\"refs\"].append(ref)\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Processed {batch_idx + 1}/{len(test_loader)} batches\")\n",
    "    \n",
    "    # Calculate overall metrics including BLEU\n",
    "    overall_rouge = calculate_rouge_scores(all_predictions, all_references)\n",
    "    overall_bleu = calculate_bleu_score(all_predictions, all_references)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Overall Test Results:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ROUGE-1: {overall_rouge['rouge1']:.4f}\")\n",
    "    print(f\"ROUGE-2: {overall_rouge['rouge2']:.4f}\")\n",
    "    print(f\"ROUGE-L: {overall_rouge['rougeL']:.4f}\")\n",
    "    print(f\"BLEU:    {overall_bleu:.2f}\")\n",
    "    \n",
    "    # Calculate per-language ROUGE and BLEU scores\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Per-Language Test Results:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    language_rouge = {}\n",
    "    for lang, data in language_performance.items():\n",
    "        if data[\"preds\"]:\n",
    "            lang_rouge = calculate_rouge_scores(data[\"preds\"], data[\"refs\"])\n",
    "            lang_bleu = calculate_bleu_score(data[\"preds\"], data[\"refs\"])\n",
    "            language_rouge[lang] = lang_rouge\n",
    "            print(f\"\\n{lang.upper()}:\")\n",
    "            print(f\"  ROUGE-1: {lang_rouge['rouge1']:.4f}\")\n",
    "            print(f\"  ROUGE-2: {lang_rouge['rouge2']:.4f}\")\n",
    "            print(f\"  ROUGE-L: {lang_rouge['rougeL']:.4f}\")\n",
    "            print(f\"  BLEU:    {lang_bleu:.2f}\")\n",
    "            print(f\"  Samples: {len(data['preds'])}\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"overall\": {**overall_rouge, \"bleu\": overall_bleu},\n",
    "        \"per_language\": language_rouge\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90a4e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_expert_specialization(model):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Expert Specialization Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    moe_layers = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, MoELayer):\n",
    "            moe_layers.append((name, module))\n",
    "    \n",
    "    if not moe_layers:\n",
    "        print(\"No MoE layers found!\")\n",
    "        return\n",
    "    \n",
    "    # Analyze each MoE layer\n",
    "    for layer_idx, (layer_name, moe_layer) in enumerate(moe_layers):\n",
    "        print(f\"\\n--- Layer {layer_idx}: {layer_name} ---\")\n",
    "        \n",
    "        # Expert usage statistics\n",
    "        usage_counts = moe_layer.expert_usage_count.cpu().numpy()\n",
    "        total_usage = usage_counts.sum()\n",
    "        \n",
    "        if total_usage == 0:\n",
    "            print(\"No usage data recorded (layer not used yet)\")\n",
    "            continue\n",
    "        \n",
    "        usage_pct = (usage_counts / total_usage) * 100\n",
    "        \n",
    "        print(f\"Total expert calls: {total_usage:.0f}\")\n",
    "        print(f\"\\nExpert Usage Distribution:\")\n",
    "        for expert_idx, (count, pct) in enumerate(zip(usage_counts, usage_pct)):\n",
    "            # Check if this is a language-specific expert\n",
    "            lang_tag = \"\"\n",
    "            for lang, mapped_idx in moe_layer.language_expert_map.items():\n",
    "                if isinstance(mapped_idx, int) and mapped_idx == expert_idx:\n",
    "                    lang_tag = f\" ({lang.upper()} expert)\"\n",
    "                elif isinstance(mapped_idx, list) and expert_idx in mapped_idx:\n",
    "                    lang_tag = f\" (shared)\"\n",
    "            \n",
    "            print(f\"  Expert {expert_idx}{lang_tag}: {count:>8.0f} calls ({pct:>5.1f}%)\")\n",
    "        \n",
    "        # Check for imbalance (ideal: ~16.67% per expert for 6 experts)\n",
    "        ideal_pct = 100.0 / config.num_experts\n",
    "        max_deviation = max(abs(pct - ideal_pct) for pct in usage_pct)\n",
    "        \n",
    "        print(f\"\\nLoad Balance Metrics:\")\n",
    "        print(f\"  Ideal usage per expert: {ideal_pct:.1f}%\")\n",
    "        print(f\"  Max deviation: {max_deviation:.1f}%\")\n",
    "        \n",
    "        if max_deviation < 5:\n",
    "            print(f\"  âœ… EXCELLENT balance (deviation < 5%)\")\n",
    "        elif max_deviation < 10:\n",
    "            print(f\"  âœ“ GOOD balance (deviation < 10%)\")\n",
    "        elif max_deviation < 20:\n",
    "            print(f\"  âš ï¸ FAIR balance (deviation < 20%)\")\n",
    "        else:\n",
    "            print(f\"  âŒ POOR balance (deviation > 20%)\")\n",
    "        \n",
    "        # Overflow statistics\n",
    "        overflow_rate = (moe_layer.overflow_count / max(moe_layer.total_forward_calls, 1)) * 100\n",
    "        print(f\"\\nCapacity Overflow:\")\n",
    "        print(f\"  Total overflow: {moe_layer.overflow_count} tokens\")\n",
    "        print(f\"  Overflow rate: {overflow_rate:.2f}%\")\n",
    "        \n",
    "        if overflow_rate < 1:\n",
    "            print(f\"  âœ… EXCELLENT (< 1%)\")\n",
    "        elif overflow_rate < 5:\n",
    "            print(f\"  âœ“ GOOD (< 5%)\")\n",
    "        elif overflow_rate < 10:\n",
    "            print(f\"  âš ï¸ FAIR (< 10%)\")\n",
    "        else:\n",
    "            print(f\"  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Visualize expert usage distribution\n",
    "    fig, axes = plt.subplots(1, min(len(moe_layers), 3), figsize=(15, 5))\n",
    "    if len(moe_layers) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (layer_name, moe_layer) in enumerate(moe_layers[:3]):\n",
    "        usage_counts = moe_layer.expert_usage_count.cpu().numpy()\n",
    "        total_usage = usage_counts.sum()\n",
    "        \n",
    "        if total_usage > 0:\n",
    "            usage_pct = (usage_counts / total_usage) * 100\n",
    "            \n",
    "            # Color experts by type\n",
    "            colors = []\n",
    "            labels = []\n",
    "            for expert_idx in range(config.num_experts):\n",
    "                is_lang_specific = False\n",
    "                for lang, mapped_idx in moe_layer.language_expert_map.items():\n",
    "                    if isinstance(mapped_idx, int) and mapped_idx == expert_idx:\n",
    "                        colors.append('skyblue')\n",
    "                        labels.append(f\"E{expert_idx}\\n{lang}\")\n",
    "                        is_lang_specific = True\n",
    "                        break\n",
    "                \n",
    "                if not is_lang_specific:\n",
    "                    colors.append('lightcoral')\n",
    "                    labels.append(f\"E{expert_idx}\\nshared\")\n",
    "            \n",
    "            axes[idx].bar(range(config.num_experts), usage_pct, color=colors)\n",
    "            axes[idx].axhline(y=100/config.num_experts, color='red', linestyle='--', \n",
    "                             label=f'Ideal ({100/config.num_experts:.1f}%)', alpha=0.7)\n",
    "            axes[idx].set_xlabel(\"Expert\")\n",
    "            axes[idx].set_ylabel(\"Usage (%)\")\n",
    "            axes[idx].set_title(f\"Layer {idx} Expert Usage\")\n",
    "            axes[idx].set_xticks(range(config.num_experts))\n",
    "            axes[idx].set_xticklabels(labels, fontsize=8)\n",
    "            axes[idx].legend()\n",
    "            axes[idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49f02f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(training_history):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    epochs = range(1, len(training_history[\"train_losses\"]) + 1)\n",
    "    \n",
    "    axes[0, 0].plot(epochs, training_history[\"train_losses\"], 'b-', label=\"Train Loss\")\n",
    "    axes[0, 0].plot(epochs, training_history[\"val_losses\"], 'r-', label=\"Val Loss\")\n",
    "    axes[0, 0].set_xlabel(\"Epoch\")\n",
    "    axes[0, 0].set_ylabel(\"Loss\")\n",
    "    axes[0, 0].set_title(\"Training and Validation Loss\")\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    rouge1 = [s[\"rouge1\"] for s in training_history[\"val_rouge_scores\"]]\n",
    "    rouge2 = [s[\"rouge2\"] for s in training_history[\"val_rouge_scores\"]]\n",
    "    rougeL = [s[\"rougeL\"] for s in training_history[\"val_rouge_scores\"]]\n",
    "    \n",
    "    axes[0, 1].plot(epochs, rouge1, 'g-', label=\"ROUGE-1\")\n",
    "    axes[0, 1].plot(epochs, rouge2, 'b-', label=\"ROUGE-2\")\n",
    "    axes[0, 1].plot(epochs, rougeL, 'r-', label=\"ROUGE-L\")\n",
    "    axes[0, 1].set_xlabel(\"Epoch\")\n",
    "    axes[0, 1].set_ylabel(\"ROUGE Score\")\n",
    "    axes[0, 1].set_title(\"Validation ROUGE Scores\")\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    if training_history.get(\"grad_norms\"):\n",
    "        steps, norms = zip(*training_history[\"grad_norms\"])\n",
    "        axes[1, 0].plot(steps, norms, 'purple', alpha=0.7)\n",
    "        axes[1, 0].set_xlabel(\"Training Step\")\n",
    "        axes[1, 0].set_ylabel(\"Gradient Norm\")\n",
    "        axes[1, 0].set_title(\"Gradient Norms During Training\")\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    if training_history.get(\"overflow_steps\"):\n",
    "        overflow_steps = training_history[\"overflow_steps\"]\n",
    "        if overflow_steps:\n",
    "            axes[1, 1].hist(overflow_steps, bins=20, color='orange', alpha=0.7)\n",
    "            axes[1, 1].set_xlabel(\"Training Step\")\n",
    "            axes[1, 1].set_ylabel(\"Frequency\")\n",
    "            axes[1, 1].set_title(f\"Gradient Overflow Distribution ({len(overflow_steps)} total)\")\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"training_curves.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Plot saved as training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fea16366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_language_performance(language_rouge):\n",
    "    languages = list(language_rouge.keys())\n",
    "    rouge1_scores = [language_rouge[lang][\"rouge1\"] for lang in languages]\n",
    "    rouge2_scores = [language_rouge[lang][\"rouge2\"] for lang in languages]\n",
    "    rougeL_scores = [language_rouge[lang][\"rougeL\"] for lang in languages]\n",
    "\n",
    "    x = np.arange(len(languages))\n",
    "    width = 0.25\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.bar(x - width, rouge1_scores, width, label=\"ROUGE-1\")\n",
    "    ax.bar(x, rouge2_scores, width, label=\"ROUGE-2\")\n",
    "    ax.bar(x + width, rougeL_scores, width, label=\"ROUGE-L\")\n",
    "\n",
    "    ax.set_xlabel(\"Languages\")\n",
    "    ax.set_ylabel(\"ROUGE Scores\")\n",
    "    ax.set_title(\"Language-Specific Performance\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(languages)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01d34810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading english data...\n",
      "  Loaded 306522 samples\n",
      "Loading hindi data...\n",
      "  Loaded 306522 samples\n",
      "Loading hindi data...\n",
      "  Loaded 70778 samples\n",
      "Loading punjabi data...\n",
      "  Loaded 70778 samples\n",
      "Loading punjabi data...\n",
      "  Loaded 8215 samples\n",
      "\n",
      "ðŸŽ¯ Target count (matching English): 306522 samples per language\n",
      "  Loaded 8215 samples\n",
      "\n",
      "ðŸŽ¯ Target count (matching English): 306522 samples per language\n",
      "âœ“ english - Train: 306522, Val: 11535, Test: 11535\n",
      "\n",
      "  Augmenting hindi from 70778 to 306522 samples...\n",
      "âœ“ english - Train: 306522, Val: 11535, Test: 11535\n",
      "\n",
      "  Augmenting hindi from 70778 to 306522 samples...\n",
      "  âœ“ hindi augmented: +235744 samples (total: 306522)\n",
      "  âœ“ Balance ratio: 1.00x relative to English\n",
      "  âœ“ hindi augmented: +235744 samples (total: 306522)\n",
      "  âœ“ Balance ratio: 1.00x relative to English\n",
      "âœ“ hindi - Train: 306522, Val: 8847, Test: 8847\n",
      "\n",
      "  Augmenting punjabi from 8215 to 306522 samples...\n",
      "âœ“ hindi - Train: 306522, Val: 8847, Test: 8847\n",
      "\n",
      "  Augmenting punjabi from 8215 to 306522 samples...\n",
      "  âœ“ punjabi augmented: +298307 samples (total: 306522)\n",
      "  âœ“ Balance ratio: 1.00x relative to English\n",
      "  âœ“ punjabi augmented: +298307 samples (total: 306522)\n",
      "  âœ“ Balance ratio: 1.00x relative to English\n",
      "âœ“ punjabi - Train: 306522, Val: 1026, Test: 1026\n",
      "\n",
      "============================================================\n",
      "TOTAL DATASET SIZES (BALANCED)\n",
      "============================================================\n",
      "Train: 919,566 samples\n",
      "Val:   21,408 samples\n",
      "Test:  21,408 samples\n",
      "âœ“ punjabi - Train: 306522, Val: 1026, Test: 1026\n",
      "\n",
      "============================================================\n",
      "TOTAL DATASET SIZES (BALANCED)\n",
      "============================================================\n",
      "Train: 919,566 samples\n",
      "Val:   21,408 samples\n",
      "Test:  21,408 samples\n",
      "\n",
      "Training Data Distribution:\n",
      "  English: 306,522 (33.3%)\n",
      "  Hindi: 306,522 (33.3%)\n",
      "  Punjabi: 306,522 (33.3%)\n",
      "============================================================\n",
      "\n",
      "\n",
      "Training Data Distribution:\n",
      "  English: 306,522 (33.3%)\n",
      "  Hindi: 306,522 (33.3%)\n",
      "  Punjabi: 306,522 (33.3%)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "train_data, val_data, test_data = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cad9928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and base model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading tokenizer and base model...\")\n",
    "tokenizer = MT5Tokenizer.from_pretrained(config.model_name, legacy=False)\n",
    "base_model = MT5ForConditionalGeneration.from_pretrained(config.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09fe831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding language-specific special tokens to tokenizer...\n",
      "Added 3 special tokens: ['<en>', '<hi>', '<pa>']\n",
      "New tokenizer vocab size: 250103\n",
      "New tokenizer vocab size: 250103\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding language-specific special tokens to tokenizer...\")\n",
    "special_tokens = [\"<en>\", \"<hi>\", \"<pa>\"]\n",
    "num_added = tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
    "print(f\"Added {num_added} special tokens: {special_tokens}\")\n",
    "print(f\"New tokenizer vocab size: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06c8b9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU cache cleared successfully\n",
      "GPU Memory - Allocated: 0.00 GB, Reserved: 0.00 GB\n",
      "GPU memory cleanup complete\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "try:\n",
    "    if 'model' in dir():\n",
    "        del model\n",
    "        print(\"Deleted existing model from memory\")\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        print(\"GPU cache cleared successfully\")\n",
    "        \n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"GPU Memory - Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Error: {str(e)}\")\n",
    "        print(\"\\n SOLUTION: Restart the kernel to clear the GPU error state\")\n",
    "        print(\"   1. Click 'Kernel' menu â†’ 'Restart Kernel'\")\n",
    "        print(\"   2. Re-run cells from the beginning\")\n",
    "        raise\n",
    "    \n",
    "gc.collect()\n",
    "\n",
    "print(\"GPU memory cleanup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99669ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MoE model for a single GPU...\n",
      "Language codes: ['en', 'hi', 'pu']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MT5WithMoE(\n",
       "  (base_model): MT5ForConditionalGeneration(\n",
       "    (shared): Embedding(250112, 512)\n",
       "    (encoder): MT5Stack(\n",
       "      (embed_tokens): Embedding(250112, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerFF(\n",
       "              (DenseReluDense): MoEWrapper(\n",
       "                (moe_layer): MoELayer(\n",
       "                  (gate_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (gate): Linear(in_features=512, out_features=6, bias=True)\n",
       "                  (experts): ModuleList(\n",
       "                    (0-5): 6 x Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (1): GELU(approximate='none')\n",
       "                      (2): Dropout(p=0.1, inplace=False)\n",
       "                      (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerFF(\n",
       "              (DenseReluDense): MoEWrapper(\n",
       "                (moe_layer): MoELayer(\n",
       "                  (gate_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (gate): Linear(in_features=512, out_features=6, bias=True)\n",
       "                  (experts): ModuleList(\n",
       "                    (0-5): 6 x Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (1): GELU(approximate='none')\n",
       "                      (2): Dropout(p=0.1, inplace=False)\n",
       "                      (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): MT5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): MT5Stack(\n",
       "      (embed_tokens): Embedding(250112, 512)\n",
       "      (block): ModuleList(\n",
       "        (0): MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 6)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerCrossAttention(\n",
       "              (EncDecAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): MT5LayerFF(\n",
       "              (DenseReluDense): MoEWrapper(\n",
       "                (moe_layer): MoELayer(\n",
       "                  (gate_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (gate): Linear(in_features=512, out_features=6, bias=True)\n",
       "                  (experts): ModuleList(\n",
       "                    (0-5): 6 x Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (1): GELU(approximate='none')\n",
       "                      (2): Dropout(p=0.1, inplace=False)\n",
       "                      (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1-7): 7 x MT5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): MT5LayerSelfAttention(\n",
       "              (SelfAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): MT5LayerCrossAttention(\n",
       "              (EncDecAttention): MT5Attention(\n",
       "                (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "                (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): MT5LayerFF(\n",
       "              (DenseReluDense): MoEWrapper(\n",
       "                (moe_layer): MoELayer(\n",
       "                  (gate_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (gate): Linear(in_features=512, out_features=6, bias=True)\n",
       "                  (experts): ModuleList(\n",
       "                    (0-5): 6 x Sequential(\n",
       "                      (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (1): GELU(approximate='none')\n",
       "                      (2): Dropout(p=0.1, inplace=False)\n",
       "                      (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (layer_norm): MT5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): MT5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Setting up MoE model for a single GPU...\")\n",
    "# Extract language codes from config (e.g., \"english\" -> \"en\")\n",
    "language_codes = [lang[:2] if len(lang) >= 2 else lang for lang in config.languages]\n",
    "print(f\"Language codes: {language_codes}\")\n",
    "\n",
    "model = MT5WithMoE(\n",
    "    base_model, \n",
    "    config.num_experts, \n",
    "    config.top_k, \n",
    "    config.capacity_factor, \n",
    "    language_codes,\n",
    "    config.expert_dropout \n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efbc1b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing token embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(250103, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Resizing token embeddings...\")\n",
    "model.base_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a37ec9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets and dataloaders...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating datasets and dataloaders...\")\n",
    "train_dataset = MultilingualSummarizationDataset(\n",
    "    tokenizer, train_data, config.max_input_length, config.max_target_length\n",
    ")\n",
    "val_dataset = MultilingualSummarizationDataset(\n",
    "    tokenizer, val_data, config.max_input_length, config.max_target_length\n",
    ")\n",
    "test_dataset = MultilingualSummarizationDataset(\n",
    "    tokenizer, test_data, config.max_input_length, config.max_target_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cec9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b4bcd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 476,639,712\n",
      "Trainable parameters: 476,639,712\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\n",
    "    f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4769a99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Configuration saved to: ./checkpoints/moe_xlsum_20251116_132710/config.json\n",
      "\n",
      " Training Dataset Statistics:\n",
      "   Train samples: 919,566\n",
      "   Val samples: 21,408\n",
      "   Test samples: 21,408\n",
      "\n",
      "Curriculum Learning: ENABLED\n",
      "   Phase 1: Shortest: 2 epochs\n",
      "   Phase 2: Short: 3 epochs\n",
      "   Phase 3: Medium: 3 epochs\n",
      "   Phase 4: Long: 2 epochs\n",
      "\n",
      "Length-Balanced Sampling: ENABLED\n"
     ]
    }
   ],
   "source": [
    "# Save configuration for reproducibility\n",
    "config_dict = {\n",
    "    \"model_name\": config.model_name,\n",
    "    \"languages\": config.languages,\n",
    "    \"optimizer\": config.optimizer,\n",
    "    \"num_experts\": config.num_experts,\n",
    "    \"top_k\": config.top_k,\n",
    "    \"capacity_factor\": config.capacity_factor,\n",
    "    \"batch_size\": config.batch_size,\n",
    "    \"gradient_accumulation_steps\": config.gradient_accumulation_steps,\n",
    "    \"effective_batch_size\": config.batch_size * config.gradient_accumulation_steps,\n",
    "    \"learning_rate\": f\"{config.learning_rate:.2e}\",\n",
    "    \"num_epochs\": config.num_epochs,\n",
    "    \"warmup_steps\": config.warmup_steps,\n",
    "    \"weight_decay\": config.weight_decay,\n",
    "    \"aux_loss_weight_start\": config.aux_loss_weight_start,\n",
    "    \"aux_loss_weight_end\": config.aux_loss_weight_end,\n",
    "    \"aux_loss_warmup_steps\": config.aux_loss_warmup_steps,\n",
    "    \"train_samples\": len(train_data),\n",
    "    \"val_samples\": len(val_data),\n",
    "    \"test_samples\": len(test_data),\n",
    "    \"train_size_limit\": config.train_size,\n",
    "    \"val_size_limit\": config.val_size,\n",
    "    \"test_size_limit\": config.test_size,\n",
    "    \"checkpoint_dir\": config.checkpoint_dir,\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(os.path.join(config.checkpoint_dir, \"config.json\"), \"w\") as f:\n",
    "    json.dump(config_dict, f, indent=2)\n",
    "\n",
    "print(\"âœ“ Configuration saved to:\", os.path.join(config.checkpoint_dir, \"config.json\"))\n",
    "print(f\"\\n Training Dataset Statistics:\")\n",
    "print(f\"   Train samples: {len(train_data):,}\")\n",
    "print(f\"   Val samples: {len(val_data):,}\")\n",
    "print(f\"   Test samples: {len(test_data):,}\")\n",
    "if config.use_curriculum:\n",
    "    print(f\"\\nCurriculum Learning: ENABLED\")\n",
    "    for phase in config.curriculum_phases:\n",
    "        print(f\"   {phase['name']}: {phase['epochs']} epochs\")\n",
    "if config.use_length_balanced_sampling:\n",
    "    print(f\"\\nLength-Balanced Sampling: ENABLED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e57b7fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL SANITY CHECK\n",
      "============================================================\n",
      "\n",
      "Total Parameters: 476,639,712\n",
      "Trainable Parameters: 476,639,712\n",
      "âœ… No NaN/Inf in model weights\n",
      "\n",
      "ðŸ§ª Testing forward pass...\n",
      "âœ… Forward pass successful\n",
      "   Initial loss: 36.9879\n",
      "============================================================\n",
      "âœ… Forward pass successful\n",
      "   Initial loss: 36.9879\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Optional: Quick sanity check on model before training\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL SANITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check parameter statistics\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "\n",
    "# Check for NaN/Inf in initial weights\n",
    "has_nan = False\n",
    "has_inf = False\n",
    "for name, param in model.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"âš ï¸  NaN detected in {name}\")\n",
    "        has_nan = True\n",
    "    if torch.isinf(param).any():\n",
    "        print(f\"âš ï¸  Inf detected in {name}\")\n",
    "        has_inf = True\n",
    "\n",
    "if not has_nan and not has_inf:\n",
    "    print(\"âœ… No NaN/Inf in model weights\")\n",
    "\n",
    "# Check gradient flow by doing a tiny forward pass\n",
    "print(\"\\nðŸ§ª Testing forward pass...\")\n",
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    with torch.cuda.amp.autocast():\n",
    "        test_outputs = model(\n",
    "            input_ids=sample_batch[\"input_ids\"][:2].to(device),\n",
    "            attention_mask=sample_batch[\"attention_mask\"][:2].to(device),\n",
    "            labels=sample_batch[\"labels\"][:2].to(device),\n",
    "            language_ids=sample_batch[\"language\"][:2],\n",
    "            aux_loss_weight=config.aux_loss_weight_start,\n",
    "            language_loss_weights=config.language_loss_weights\n",
    "        )\n",
    "    print(f\"âœ… Forward pass successful\")\n",
    "    print(f\"   Initial loss: {test_outputs.loss.item():.4f}\")\n",
    "    \n",
    "    if test_outputs.loss.item() > 100:\n",
    "        print(f\"   âš ï¸  Loss is very high - this is expected initially\")\n",
    "        print(f\"   It should decrease rapidly in first few steps\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Forward pass failed: {e}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5759c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING MODEL WITH OPTIMIZED HYPERPARAMETERS\n",
      "======================================================================\n",
      "\n",
      "Optimal Configuration:\n",
      "  Learning Rate: 3.00e-02\n",
      "  Batch Size: 16\n",
      "  Gradient Accumulation: 4\n",
      "  Effective Batch Size: 64\n",
      "  Epochs: 10\n",
      "  Warmup Steps: 2000\n",
      "  Weight Decay: 0.01\n",
      "  Gradient Clip: 0.5\n",
      "  Aux Loss Weight: 0.002\n",
      "  Expert Dropout: 0.1\n",
      "\n",
      "Dataset:\n",
      "  Training Samples: 919566\n",
      "  Validation Samples: 21408\n",
      "  Test Samples: 21408\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ“ CURRICULUM LEARNING ENABLED\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š Phase 1: Shortest\n",
      "   Max Input Length: 128\n",
      "   Max Target Length: 32\n",
      "   Epochs: 2\n",
      "======================================================================\n",
      "\n",
      "Phase 1 Data: 38624 training samples\n",
      "Phase 1 Data: 38624 training samples\n",
      "\n",
      "âœ“ Using Muon optimizer with LR=3.00e-02\n",
      "  - Muon params: 307 (2D+ weights)\n",
      "  - AdamW params: 283 (embeddings, biases, norms)\n",
      "\n",
      "\n",
      "âš¡ Training in full FP32 precision (no AMP) for maximum stability\n",
      "\n",
      "Training: 2 epochs, 1207 steps, batch size 64\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 1/2\n",
      "============================================================\n",
      "\n",
      "âœ“ Using Muon optimizer with LR=3.00e-02\n",
      "  - Muon params: 307 (2D+ weights)\n",
      "  - AdamW params: 283 (embeddings, biases, norms)\n",
      "\n",
      "\n",
      "âš¡ Training in full FP32 precision (no AMP) for maximum stability\n",
      "\n",
      "Training: 2 epochs, 1207 steps, batch size 64\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 1/2\n",
      "============================================================\n",
      "Step 500 | Loss: 13.3941 | LR: 7.50e-03\n",
      "Step 500 | Loss: 13.3941 | LR: 7.50e-03\n",
      "Step 500 | Loss: 13.3901 | LR: 7.50e-03\n",
      "Step 500 | Loss: 13.3901 | LR: 7.50e-03\n",
      "Step 500 | Loss: 13.3863 | LR: 7.50e-03\n",
      "Step 500 | Loss: 13.3825 | LR: 7.50e-03\n",
      "Step 500 | Loss: 13.3863 | LR: 7.50e-03\n",
      "Step 500 | Loss: 13.3825 | LR: 7.50e-03\n",
      "\n",
      "Validating epoch 1...\n",
      "\n",
      "Validating epoch 1...\n",
      "Epoch 1: Train Loss=12.0571, Val Loss=6.1413, R1=0.1195, R2=0.0149, RL=0.0863, BLEU=9.26, Time=11.2min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.0729/8.05 HI=0.0935/27.50 PA=0.0924/11.25 \n",
      "\n",
      "Epoch 1: Train Loss=12.0571, Val Loss=6.1413, R1=0.1195, R2=0.0149, RL=0.0863, BLEU=9.26, Time=11.2min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.0729/8.05 HI=0.0935/27.50 PA=0.0924/11.25 \n",
      "\n",
      "New best model saved! rougeL: 0.0863 (epoch 0)\n",
      "New best model saved! rougeL: 0.0863 (epoch 0)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/2\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 2/2\n",
      "============================================================\n",
      "Step 1000 | Loss: 4.1972 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 4.1972 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 4.1972 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 4.1972 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 4.1975 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 4.1975 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 4.1975 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 4.1975 | LR: 1.50e-02\n",
      "\n",
      "Validating epoch 2...\n",
      "\n",
      "Validating epoch 2...\n",
      "Epoch 2: Train Loss=3.9276, Val Loss=5.3746, R1=0.1255, R2=0.0198, RL=0.0905, BLEU=21.36, Time=22.7min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.0811/21.36 HI=0.0915/26.29 PA=0.0990/25.15 \n",
      "\n",
      "Epoch 2: Train Loss=3.9276, Val Loss=5.3746, R1=0.1255, R2=0.0198, RL=0.0905, BLEU=21.36, Time=22.7min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.0811/21.36 HI=0.0915/26.29 PA=0.0990/25.15 \n",
      "\n",
      "New best model saved! rougeL: 0.0905 (epoch 1)\n",
      "New best model saved! rougeL: 0.0905 (epoch 1)\n",
      "No improvement. Patience: 1/5\n",
      "\n",
      "Training completed! Best rougeL: 0.0905 at epoch 1\n",
      "\n",
      "\n",
      "âœ… Phase 1: Shortest completed!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š Phase 2: Short\n",
      "   Max Input Length: 256\n",
      "   Max Target Length: 64\n",
      "   Epochs: 3\n",
      "======================================================================\n",
      "\n",
      "No improvement. Patience: 1/5\n",
      "\n",
      "Training completed! Best rougeL: 0.0905 at epoch 1\n",
      "\n",
      "\n",
      "âœ… Phase 1: Shortest completed!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š Phase 2: Short\n",
      "   Max Input Length: 256\n",
      "   Max Target Length: 64\n",
      "   Epochs: 3\n",
      "======================================================================\n",
      "\n",
      "Phase 2 Data: 187741 training samples\n",
      "Phase 2 Data: 187741 training samples\n",
      "\n",
      "âœ“ Using Muon optimizer with LR=3.00e-02\n",
      "  - Muon params: 307 (2D+ weights)\n",
      "  - AdamW params: 283 (embeddings, biases, norms)\n",
      "\n",
      "\n",
      "âš¡ Training in full FP32 precision (no AMP) for maximum stability\n",
      "\n",
      "Training: 3 epochs, 8800 steps, batch size 64\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 1/3\n",
      "============================================================\n",
      "\n",
      "âœ“ Using Muon optimizer with LR=3.00e-02\n",
      "  - Muon params: 307 (2D+ weights)\n",
      "  - AdamW params: 283 (embeddings, biases, norms)\n",
      "\n",
      "\n",
      "âš¡ Training in full FP32 precision (no AMP) for maximum stability\n",
      "\n",
      "Training: 3 epochs, 8800 steps, batch size 64\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 1/3\n",
      "============================================================\n",
      "Step 500 | Loss: 3.5140 | LR: 7.50e-03\n",
      "Step 500 | Loss: 3.5140 | LR: 7.50e-03\n",
      "Step 500 | Loss: 3.5137 | LR: 7.50e-03\n",
      "Step 500 | Loss: 3.5137 | LR: 7.50e-03\n",
      "Step 500 | Loss: 3.5137 | LR: 7.50e-03\n",
      "Step 500 | Loss: 3.5135 | LR: 7.50e-03\n",
      "Step 500 | Loss: 3.5137 | LR: 7.50e-03\n",
      "Step 500 | Loss: 3.5135 | LR: 7.50e-03\n",
      "Step 1000 | Loss: 3.1807 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 3.1807 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 3.1809 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 3.1809 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 3.1808 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 3.1806 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 3.1808 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 3.1806 | LR: 1.50e-02\n",
      "Step 1500 | Loss: 2.9985 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 2.9983 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 2.9985 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 2.9983 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 2.9982 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 2.9981 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 2.9982 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 2.9981 | LR: 2.25e-02\n",
      "Step 2000 | Loss: 2.8778 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 2.8778 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 2.8779 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 2.8779 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 2.8778 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 2.8778 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 2.8778 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 2.8778 | LR: 3.00e-02\n",
      "Step 2500 | Loss: 2.7821 | LR: 2.78e-02\n",
      "Step 2500 | Loss: 2.7821 | LR: 2.78e-02\n",
      "Step 2500 | Loss: 2.7821 | LR: 2.78e-02\n",
      "Step 2500 | Loss: 2.7821 | LR: 2.78e-02\n",
      "Step 2500 | Loss: 2.7820 | LR: 2.78e-02\n",
      "Step 2500 | Loss: 2.7820 | LR: 2.78e-02\n",
      "Step 2500 | Loss: 2.7820 | LR: 2.78e-02\n",
      "Step 2500 | Loss: 2.7820 | LR: 2.78e-02\n",
      "\n",
      "Validating epoch 1...\n",
      "\n",
      "Validating epoch 1...\n",
      "Epoch 1: Train Loss=2.7043, Val Loss=2.8853, R1=0.1453, R2=0.0286, RL=0.1059, BLEU=5.29, Time=49.0min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.0998/2.81 HI=0.1125/25.26 PA=0.1053/21.87 \n",
      "\n",
      "Epoch 1: Train Loss=2.7043, Val Loss=2.8853, R1=0.1453, R2=0.0286, RL=0.1059, BLEU=5.29, Time=49.0min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.0998/2.81 HI=0.1125/25.26 PA=0.1053/21.87 \n",
      "\n",
      "New best model saved! rougeL: 0.1059 (epoch 0)\n",
      "New best model saved! rougeL: 0.1059 (epoch 0)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/3\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 2/3\n",
      "============================================================\n",
      "Step 3000 | Loss: 2.1062 | LR: 2.56e-02\n",
      "Step 3000 | Loss: 2.1069 | LR: 2.56e-02\n",
      "Step 3000 | Loss: 2.1062 | LR: 2.56e-02\n",
      "Step 3000 | Loss: 2.1069 | LR: 2.56e-02\n",
      "Step 3000 | Loss: 2.1090 | LR: 2.56e-02\n",
      "Step 3000 | Loss: 2.1074 | LR: 2.56e-02\n",
      "Step 3000 | Loss: 2.1090 | LR: 2.56e-02\n",
      "Step 3000 | Loss: 2.1074 | LR: 2.56e-02\n",
      "Step 3500 | Loss: 2.1056 | LR: 2.34e-02\n",
      "Step 3500 | Loss: 2.1056 | LR: 2.34e-02\n",
      "Step 3500 | Loss: 2.1056 | LR: 2.34e-02\n",
      "Step 3500 | Loss: 2.1056 | LR: 2.34e-02\n",
      "Step 3500 | Loss: 2.1057 | LR: 2.34e-02\n",
      "Step 3500 | Loss: 2.1057 | LR: 2.34e-02\n",
      "Step 3500 | Loss: 2.1057 | LR: 2.34e-02\n",
      "Step 3500 | Loss: 2.1057 | LR: 2.34e-02\n",
      "Step 4000 | Loss: 2.0659 | LR: 2.12e-02\n",
      "Step 4000 | Loss: 2.0660 | LR: 2.12e-02\n",
      "Step 4000 | Loss: 2.0659 | LR: 2.12e-02\n",
      "Step 4000 | Loss: 2.0660 | LR: 2.12e-02\n",
      "Step 4000 | Loss: 2.0659 | LR: 2.12e-02\n",
      "Step 4000 | Loss: 2.0659 | LR: 2.12e-02\n",
      "Step 4000 | Loss: 2.0659 | LR: 2.12e-02\n",
      "Step 4000 | Loss: 2.0659 | LR: 2.12e-02\n",
      "Step 4500 | Loss: 2.0332 | LR: 1.90e-02\n",
      "Step 4500 | Loss: 2.0331 | LR: 1.90e-02\n",
      "Step 4500 | Loss: 2.0332 | LR: 1.90e-02\n",
      "Step 4500 | Loss: 2.0331 | LR: 1.90e-02\n",
      "Step 4500 | Loss: 2.0331 | LR: 1.90e-02\n",
      "Step 4500 | Loss: 2.0331 | LR: 1.90e-02\n",
      "Step 4500 | Loss: 2.0331 | LR: 1.90e-02\n",
      "Step 4500 | Loss: 2.0331 | LR: 1.90e-02\n",
      "Step 5000 | Loss: 1.9989 | LR: 1.68e-02\n",
      "Step 5000 | Loss: 1.9989 | LR: 1.68e-02\n",
      "Step 5000 | Loss: 1.9989 | LR: 1.68e-02\n",
      "Step 5000 | Loss: 1.9989 | LR: 1.68e-02\n",
      "Step 5000 | Loss: 1.9988 | LR: 1.68e-02\n",
      "Step 5000 | Loss: 1.9988 | LR: 1.68e-02\n",
      "Step 5000 | Loss: 1.9988 | LR: 1.68e-02\n",
      "Step 5000 | Loss: 1.9988 | LR: 1.68e-02\n",
      "Step 5500 | Loss: 1.9662 | LR: 1.46e-02\n",
      "Step 5500 | Loss: 1.9662 | LR: 1.46e-02\n",
      "Step 5500 | Loss: 1.9662 | LR: 1.46e-02\n",
      "Step 5500 | Loss: 1.9662 | LR: 1.46e-02\n",
      "Step 5500 | Loss: 1.9662 | LR: 1.46e-02\n",
      "Step 5500 | Loss: 1.9662 | LR: 1.46e-02\n",
      "Step 5500 | Loss: 1.9662 | LR: 1.46e-02\n",
      "Step 5500 | Loss: 1.9662 | LR: 1.46e-02\n",
      "\n",
      "Validating epoch 2...\n",
      "\n",
      "Validating epoch 2...\n",
      "Epoch 2: Train Loss=1.9417, Val Loss=2.8501, R1=0.1513, R2=0.0350, RL=0.1098, BLEU=10.14, Time=97.1min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.0988/4.86 HI=0.1145/37.63 PA=0.1161/20.62 \n",
      "\n",
      "Epoch 2: Train Loss=1.9417, Val Loss=2.8501, R1=0.1513, R2=0.0350, RL=0.1098, BLEU=10.14, Time=97.1min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.0988/4.86 HI=0.1145/37.63 PA=0.1161/20.62 \n",
      "\n",
      "New best model saved! rougeL: 0.1098 (epoch 1)\n",
      "New best model saved! rougeL: 0.1098 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/3\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 3/3\n",
      "============================================================\n",
      "Step 6000 | Loss: 1.6355 | LR: 1.24e-02\n",
      "Step 6000 | Loss: 1.6350 | LR: 1.24e-02\n",
      "Step 6000 | Loss: 1.6355 | LR: 1.24e-02\n",
      "Step 6000 | Loss: 1.6350 | LR: 1.24e-02\n",
      "Step 6000 | Loss: 1.6344 | LR: 1.24e-02\n",
      "Step 6000 | Loss: 1.6343 | LR: 1.24e-02\n",
      "Step 6000 | Loss: 1.6344 | LR: 1.24e-02\n",
      "Step 6000 | Loss: 1.6343 | LR: 1.24e-02\n",
      "Step 6500 | Loss: 1.6109 | LR: 1.01e-02\n",
      "Step 6500 | Loss: 1.6108 | LR: 1.01e-02\n",
      "Step 6500 | Loss: 1.6109 | LR: 1.01e-02\n",
      "Step 6500 | Loss: 1.6108 | LR: 1.01e-02\n",
      "Step 6500 | Loss: 1.6108 | LR: 1.01e-02\n",
      "Step 6500 | Loss: 1.6106 | LR: 1.01e-02\n",
      "Step 6500 | Loss: 1.6108 | LR: 1.01e-02\n",
      "Step 6500 | Loss: 1.6106 | LR: 1.01e-02\n",
      "Step 7000 | Loss: 1.5836 | LR: 7.94e-03\n",
      "Step 7000 | Loss: 1.5835 | LR: 7.94e-03\n",
      "Step 7000 | Loss: 1.5836 | LR: 7.94e-03\n",
      "Step 7000 | Loss: 1.5835 | LR: 7.94e-03\n",
      "Step 7000 | Loss: 1.5836 | LR: 7.94e-03\n",
      "Step 7000 | Loss: 1.5835 | LR: 7.94e-03\n",
      "Step 7000 | Loss: 1.5836 | LR: 7.94e-03\n",
      "Step 7000 | Loss: 1.5835 | LR: 7.94e-03\n",
      "Step 7500 | Loss: 1.5525 | LR: 5.74e-03\n",
      "Step 7500 | Loss: 1.5525 | LR: 5.74e-03\n",
      "Step 7500 | Loss: 1.5525 | LR: 5.74e-03\n",
      "Step 7500 | Loss: 1.5525 | LR: 5.74e-03\n",
      "Step 7500 | Loss: 1.5525 | LR: 5.74e-03\n",
      "Step 7500 | Loss: 1.5525 | LR: 5.74e-03\n",
      "Step 7500 | Loss: 1.5525 | LR: 5.74e-03\n",
      "Step 7500 | Loss: 1.5525 | LR: 5.74e-03\n",
      "Step 8000 | Loss: 1.5245 | LR: 3.53e-03\n",
      "Step 8000 | Loss: 1.5245 | LR: 3.53e-03\n",
      "Step 8000 | Loss: 1.5245 | LR: 3.53e-03\n",
      "Step 8000 | Loss: 1.5245 | LR: 3.53e-03\n",
      "Step 8000 | Loss: 1.5245 | LR: 3.53e-03\n",
      "Step 8000 | Loss: 1.5244 | LR: 3.53e-03\n",
      "Step 8000 | Loss: 1.5245 | LR: 3.53e-03\n",
      "Step 8000 | Loss: 1.5244 | LR: 3.53e-03\n",
      "Step 8500 | Loss: 1.4944 | LR: 1.32e-03\n",
      "Step 8500 | Loss: 1.4944 | LR: 1.32e-03\n",
      "Step 8500 | Loss: 1.4944 | LR: 1.32e-03\n",
      "Step 8500 | Loss: 1.4944 | LR: 1.32e-03\n",
      "Step 8500 | Loss: 1.4944 | LR: 1.32e-03\n",
      "Step 8500 | Loss: 1.4943 | LR: 1.32e-03\n",
      "Step 8500 | Loss: 1.4944 | LR: 1.32e-03\n",
      "Step 8500 | Loss: 1.4943 | LR: 1.32e-03\n",
      "\n",
      "Validating epoch 3...\n",
      "\n",
      "Validating epoch 3...\n",
      "Epoch 3: Train Loss=1.4790, Val Loss=2.9833, R1=0.1580, R2=0.0411, RL=0.1193, BLEU=6.98, Time=144.8min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1061/4.78 HI=0.1256/20.63 PA=0.1264/26.93 \n",
      "\n",
      "Epoch 3: Train Loss=1.4790, Val Loss=2.9833, R1=0.1580, R2=0.0411, RL=0.1193, BLEU=6.98, Time=144.8min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1061/4.78 HI=0.1256/20.63 PA=0.1264/26.93 \n",
      "\n",
      "New best model saved! rougeL: 0.1193 (epoch 2)\n",
      "New best model saved! rougeL: 0.1193 (epoch 2)\n",
      "No improvement. Patience: 1/5\n",
      "\n",
      "Training completed! Best rougeL: 0.1193 at epoch 2\n",
      "\n",
      "\n",
      "âœ… Phase 2: Short completed!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š Phase 3: Medium\n",
      "   Max Input Length: 384\n",
      "   Max Target Length: 96\n",
      "   Epochs: 3\n",
      "======================================================================\n",
      "\n",
      "No improvement. Patience: 1/5\n",
      "\n",
      "Training completed! Best rougeL: 0.1193 at epoch 2\n",
      "\n",
      "\n",
      "âœ… Phase 2: Short completed!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š Phase 3: Medium\n",
      "   Max Input Length: 384\n",
      "   Max Target Length: 96\n",
      "   Epochs: 3\n",
      "======================================================================\n",
      "\n",
      "Phase 3 Data: 359722 training samples\n",
      "Phase 3 Data: 359722 training samples\n",
      "\n",
      "âœ“ Using Muon optimizer with LR=3.00e-02\n",
      "  - Muon params: 307 (2D+ weights)\n",
      "  - AdamW params: 283 (embeddings, biases, norms)\n",
      "\n",
      "\n",
      "âš¡ Training in full FP32 precision (no AMP) for maximum stability\n",
      "\n",
      "Training: 3 epochs, 16862 steps, batch size 64\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 1/3\n",
      "============================================================\n",
      "\n",
      "âœ“ Using Muon optimizer with LR=3.00e-02\n",
      "  - Muon params: 307 (2D+ weights)\n",
      "  - AdamW params: 283 (embeddings, biases, norms)\n",
      "\n",
      "\n",
      "âš¡ Training in full FP32 precision (no AMP) for maximum stability\n",
      "\n",
      "Training: 3 epochs, 16862 steps, batch size 64\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 1/3\n",
      "============================================================\n",
      "Step 500 | Loss: 1.5286 | LR: 7.50e-03\n",
      "Step 500 | Loss: 1.5286 | LR: 7.50e-03\n",
      "Step 500 | Loss: 1.5285 | LR: 7.50e-03\n",
      "Step 500 | Loss: 1.5285 | LR: 7.50e-03\n",
      "Step 500 | Loss: 1.5284 | LR: 7.50e-03\n",
      "Step 500 | Loss: 1.5284 | LR: 7.50e-03\n",
      "Step 500 | Loss: 1.5286 | LR: 7.50e-03\n",
      "Step 500 | Loss: 1.5286 | LR: 7.50e-03\n",
      "Step 1000 | Loss: 1.4576 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 1.4576 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 1.4577 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 1.4577 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 1.4576 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 1.4576 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 1.4576 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 1.4576 | LR: 1.50e-02\n",
      "Step 1500 | Loss: 1.4539 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.4539 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.4539 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.4539 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.4539 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.4539 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.4539 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.4539 | LR: 2.25e-02\n",
      "Step 2000 | Loss: 1.4834 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.4834 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.4834 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.4834 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.4834 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.4834 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.4834 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.4834 | LR: 3.00e-02\n",
      "Step 2500 | Loss: 1.5151 | LR: 2.90e-02\n",
      "Step 2500 | Loss: 1.5151 | LR: 2.90e-02\n",
      "Step 2500 | Loss: 1.5151 | LR: 2.90e-02\n",
      "Step 2500 | Loss: 1.5151 | LR: 2.90e-02\n",
      "Step 2500 | Loss: 1.5151 | LR: 2.90e-02\n",
      "Step 2500 | Loss: 1.5151 | LR: 2.90e-02\n",
      "Step 2500 | Loss: 1.5152 | LR: 2.90e-02\n",
      "Step 2500 | Loss: 1.5152 | LR: 2.90e-02\n",
      "Step 3000 | Loss: 1.5302 | LR: 2.80e-02\n",
      "Step 3000 | Loss: 1.5302 | LR: 2.80e-02\n",
      "Step 3000 | Loss: 1.5302 | LR: 2.80e-02\n",
      "Step 3000 | Loss: 1.5302 | LR: 2.80e-02\n",
      "Step 3000 | Loss: 1.5302 | LR: 2.80e-02\n",
      "Step 3000 | Loss: 1.5302 | LR: 2.80e-02\n",
      "Step 3000 | Loss: 1.5302 | LR: 2.80e-02\n",
      "Step 3000 | Loss: 1.5302 | LR: 2.80e-02\n",
      "Step 3500 | Loss: 1.5365 | LR: 2.70e-02\n",
      "Step 3500 | Loss: 1.5365 | LR: 2.70e-02\n",
      "Step 3500 | Loss: 1.5365 | LR: 2.70e-02\n",
      "Step 3500 | Loss: 1.5365 | LR: 2.70e-02\n",
      "Step 3500 | Loss: 1.5365 | LR: 2.70e-02\n",
      "Step 3500 | Loss: 1.5365 | LR: 2.70e-02\n",
      "Step 3500 | Loss: 1.5365 | LR: 2.70e-02\n",
      "Step 3500 | Loss: 1.5365 | LR: 2.70e-02\n",
      "Step 4000 | Loss: 1.5371 | LR: 2.60e-02\n",
      "Step 4000 | Loss: 1.5371 | LR: 2.60e-02\n",
      "Step 4000 | Loss: 1.5371 | LR: 2.60e-02\n",
      "Step 4000 | Loss: 1.5371 | LR: 2.60e-02\n",
      "Step 4000 | Loss: 1.5371 | LR: 2.60e-02\n",
      "Step 4000 | Loss: 1.5371 | LR: 2.60e-02\n",
      "Step 4000 | Loss: 1.5371 | LR: 2.60e-02\n",
      "Step 4000 | Loss: 1.5371 | LR: 2.60e-02\n",
      "Step 4500 | Loss: 1.5348 | LR: 2.50e-02\n",
      "Step 4500 | Loss: 1.5348 | LR: 2.50e-02\n",
      "Step 4500 | Loss: 1.5348 | LR: 2.50e-02\n",
      "Step 4500 | Loss: 1.5348 | LR: 2.50e-02\n",
      "Step 4500 | Loss: 1.5348 | LR: 2.50e-02\n",
      "Step 4500 | Loss: 1.5348 | LR: 2.50e-02\n",
      "Step 4500 | Loss: 1.5348 | LR: 2.50e-02\n",
      "Step 4500 | Loss: 1.5348 | LR: 2.50e-02\n",
      "Step 5000 | Loss: 1.5301 | LR: 2.39e-02\n",
      "Step 5000 | Loss: 1.5301 | LR: 2.39e-02\n",
      "Step 5000 | Loss: 1.5301 | LR: 2.39e-02\n",
      "Step 5000 | Loss: 1.5301 | LR: 2.39e-02\n",
      "Step 5000 | Loss: 1.5301 | LR: 2.39e-02\n",
      "Step 5000 | Loss: 1.5301 | LR: 2.39e-02\n",
      "Step 5000 | Loss: 1.5300 | LR: 2.39e-02\n",
      "Step 5000 | Loss: 1.5300 | LR: 2.39e-02\n",
      "Step 5500 | Loss: 1.5243 | LR: 2.29e-02\n",
      "Step 5500 | Loss: 1.5243 | LR: 2.29e-02\n",
      "Step 5500 | Loss: 1.5243 | LR: 2.29e-02\n",
      "Step 5500 | Loss: 1.5243 | LR: 2.29e-02\n",
      "Step 5500 | Loss: 1.5243 | LR: 2.29e-02\n",
      "Step 5500 | Loss: 1.5243 | LR: 2.29e-02\n",
      "Step 5500 | Loss: 1.5243 | LR: 2.29e-02\n",
      "Step 5500 | Loss: 1.5243 | LR: 2.29e-02\n",
      "\n",
      "Validating epoch 1...\n",
      "\n",
      "Validating epoch 1...\n",
      "Epoch 1: Train Loss=1.5226, Val Loss=1.8345, R1=0.1545, R2=0.0354, RL=0.1134, BLEU=4.99, Time=96.9min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1055/4.90 HI=0.1154/14.77 PA=0.1194/9.71 \n",
      "\n",
      "Epoch 1: Train Loss=1.5226, Val Loss=1.8345, R1=0.1545, R2=0.0354, RL=0.1134, BLEU=4.99, Time=96.9min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1055/4.90 HI=0.1154/14.77 PA=0.1194/9.71 \n",
      "\n",
      "New best model saved! rougeL: 0.1134 (epoch 0)\n",
      "New best model saved! rougeL: 0.1134 (epoch 0)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/3\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 2/3\n",
      "============================================================\n",
      "Step 6000 | Loss: 1.4023 | LR: 2.19e-02\n",
      "Step 6000 | Loss: 1.4023 | LR: 2.19e-02\n",
      "Step 6000 | Loss: 1.4021 | LR: 2.19e-02\n",
      "Step 6000 | Loss: 1.4021 | LR: 2.19e-02\n",
      "Step 6000 | Loss: 1.4021 | LR: 2.19e-02\n",
      "Step 6000 | Loss: 1.4021 | LR: 2.19e-02\n",
      "Step 6000 | Loss: 1.4021 | LR: 2.19e-02\n",
      "Step 6000 | Loss: 1.4021 | LR: 2.19e-02\n",
      "Step 6500 | Loss: 1.4026 | LR: 2.09e-02\n",
      "Step 6500 | Loss: 1.4026 | LR: 2.09e-02\n",
      "Step 6500 | Loss: 1.4026 | LR: 2.09e-02\n",
      "Step 6500 | Loss: 1.4026 | LR: 2.09e-02\n",
      "Step 6500 | Loss: 1.4026 | LR: 2.09e-02\n",
      "Step 6500 | Loss: 1.4026 | LR: 2.09e-02\n",
      "Step 6500 | Loss: 1.4025 | LR: 2.09e-02\n",
      "Step 6500 | Loss: 1.4025 | LR: 2.09e-02\n",
      "Step 7000 | Loss: 1.3960 | LR: 1.99e-02\n",
      "Step 7000 | Loss: 1.3960 | LR: 1.99e-02\n",
      "Step 7000 | Loss: 1.3960 | LR: 1.99e-02\n",
      "Step 7000 | Loss: 1.3960 | LR: 1.99e-02\n",
      "Step 7000 | Loss: 1.3961 | LR: 1.99e-02\n",
      "Step 7000 | Loss: 1.3961 | LR: 1.99e-02\n",
      "Step 7000 | Loss: 1.3960 | LR: 1.99e-02\n",
      "Step 7000 | Loss: 1.3960 | LR: 1.99e-02\n",
      "Step 7500 | Loss: 1.3919 | LR: 1.89e-02\n",
      "Step 7500 | Loss: 1.3919 | LR: 1.89e-02\n",
      "Step 7500 | Loss: 1.3919 | LR: 1.89e-02\n",
      "Step 7500 | Loss: 1.3919 | LR: 1.89e-02\n",
      "Step 7500 | Loss: 1.3919 | LR: 1.89e-02\n",
      "Step 7500 | Loss: 1.3919 | LR: 1.89e-02\n",
      "Step 7500 | Loss: 1.3919 | LR: 1.89e-02\n",
      "Step 7500 | Loss: 1.3919 | LR: 1.89e-02\n",
      "Step 8000 | Loss: 1.3819 | LR: 1.79e-02\n",
      "Step 8000 | Loss: 1.3819 | LR: 1.79e-02\n",
      "Step 8000 | Loss: 1.3819 | LR: 1.79e-02\n",
      "Step 8000 | Loss: 1.3819 | LR: 1.79e-02\n",
      "Step 8000 | Loss: 1.3819 | LR: 1.79e-02\n",
      "Step 8000 | Loss: 1.3819 | LR: 1.79e-02\n",
      "Step 8000 | Loss: 1.3818 | LR: 1.79e-02\n",
      "Step 8000 | Loss: 1.3818 | LR: 1.79e-02\n",
      "Step 8500 | Loss: 1.3736 | LR: 1.69e-02\n",
      "Step 8500 | Loss: 1.3736 | LR: 1.69e-02\n",
      "Step 8500 | Loss: 1.3736 | LR: 1.69e-02\n",
      "Step 8500 | Loss: 1.3736 | LR: 1.69e-02\n",
      "Step 8500 | Loss: 1.3737 | LR: 1.69e-02\n",
      "Step 8500 | Loss: 1.3737 | LR: 1.69e-02\n",
      "Step 8500 | Loss: 1.3736 | LR: 1.69e-02\n",
      "Step 8500 | Loss: 1.3736 | LR: 1.69e-02\n",
      "Step 9000 | Loss: 1.3664 | LR: 1.59e-02\n",
      "Step 9000 | Loss: 1.3664 | LR: 1.59e-02\n",
      "Step 9000 | Loss: 1.3664 | LR: 1.59e-02\n",
      "Step 9000 | Loss: 1.3664 | LR: 1.59e-02\n",
      "Step 9000 | Loss: 1.3664 | LR: 1.59e-02\n",
      "Step 9000 | Loss: 1.3664 | LR: 1.59e-02\n",
      "Step 9000 | Loss: 1.3664 | LR: 1.59e-02\n",
      "Step 9000 | Loss: 1.3664 | LR: 1.59e-02\n",
      "Step 9500 | Loss: 1.3572 | LR: 1.49e-02\n",
      "Step 9500 | Loss: 1.3572 | LR: 1.49e-02\n",
      "Step 9500 | Loss: 1.3572 | LR: 1.49e-02\n",
      "Step 9500 | Loss: 1.3572 | LR: 1.49e-02\n",
      "Step 9500 | Loss: 1.3573 | LR: 1.49e-02\n",
      "Step 9500 | Loss: 1.3573 | LR: 1.49e-02\n",
      "Step 9500 | Loss: 1.3573 | LR: 1.49e-02\n",
      "Step 9500 | Loss: 1.3573 | LR: 1.49e-02\n",
      "Step 10000 | Loss: 1.3479 | LR: 1.39e-02\n",
      "Step 10000 | Loss: 1.3479 | LR: 1.39e-02\n",
      "Step 10000 | Loss: 1.3479 | LR: 1.39e-02\n",
      "Step 10000 | Loss: 1.3479 | LR: 1.39e-02\n",
      "Step 10000 | Loss: 1.3479 | LR: 1.39e-02\n",
      "Step 10000 | Loss: 1.3479 | LR: 1.39e-02\n",
      "Step 10000 | Loss: 1.3480 | LR: 1.39e-02\n",
      "Step 10000 | Loss: 1.3480 | LR: 1.39e-02\n",
      "Step 10500 | Loss: 1.3394 | LR: 1.28e-02\n",
      "Step 10500 | Loss: 1.3394 | LR: 1.28e-02\n",
      "Step 10500 | Loss: 1.3394 | LR: 1.28e-02\n",
      "Step 10500 | Loss: 1.3394 | LR: 1.28e-02\n",
      "Step 10500 | Loss: 1.3393 | LR: 1.28e-02\n",
      "Step 10500 | Loss: 1.3393 | LR: 1.28e-02\n",
      "Step 10500 | Loss: 1.3394 | LR: 1.28e-02\n",
      "Step 10500 | Loss: 1.3394 | LR: 1.28e-02\n",
      "Step 11000 | Loss: 1.3291 | LR: 1.18e-02\n",
      "Step 11000 | Loss: 1.3291 | LR: 1.18e-02\n",
      "Step 11000 | Loss: 1.3291 | LR: 1.18e-02\n",
      "Step 11000 | Loss: 1.3291 | LR: 1.18e-02\n",
      "Step 11000 | Loss: 1.3291 | LR: 1.18e-02\n",
      "Step 11000 | Loss: 1.3291 | LR: 1.18e-02\n",
      "Step 11000 | Loss: 1.3291 | LR: 1.18e-02\n",
      "Step 11000 | Loss: 1.3291 | LR: 1.18e-02\n",
      "\n",
      "Validating epoch 2...\n",
      "\n",
      "Validating epoch 2...\n",
      "Epoch 2: Train Loss=1.3244, Val Loss=1.8056, R1=0.1615, R2=0.0401, RL=0.1189, BLEU=5.41, Time=194.7min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1065/3.15 HI=0.1304/25.07 PA=0.1197/33.57 \n",
      "\n",
      "Epoch 2: Train Loss=1.3244, Val Loss=1.8056, R1=0.1615, R2=0.0401, RL=0.1189, BLEU=5.41, Time=194.7min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1065/3.15 HI=0.1304/25.07 PA=0.1197/33.57 \n",
      "\n",
      "New best model saved! rougeL: 0.1189 (epoch 1)\n",
      "New best model saved! rougeL: 0.1189 (epoch 1)\n",
      "\n",
      "============================================================\n",
      "Epoch 3/3\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 3/3\n",
      "============================================================\n",
      "Step 11500 | Loss: 1.1462 | LR: 1.08e-02\n",
      "Step 11500 | Loss: 1.1462 | LR: 1.08e-02\n",
      "Step 11500 | Loss: 1.1464 | LR: 1.08e-02\n",
      "Step 11500 | Loss: 1.1464 | LR: 1.08e-02\n",
      "Step 11500 | Loss: 1.1463 | LR: 1.08e-02\n",
      "Step 11500 | Loss: 1.1463 | LR: 1.08e-02\n",
      "Step 11500 | Loss: 1.1465 | LR: 1.08e-02\n",
      "Step 11500 | Loss: 1.1465 | LR: 1.08e-02\n",
      "Step 12000 | Loss: 1.1421 | LR: 9.81e-03\n",
      "Step 12000 | Loss: 1.1421 | LR: 9.81e-03\n",
      "Step 12000 | Loss: 1.1422 | LR: 9.81e-03\n",
      "Step 12000 | Loss: 1.1422 | LR: 9.81e-03\n",
      "Step 12000 | Loss: 1.1422 | LR: 9.81e-03\n",
      "Step 12000 | Loss: 1.1422 | LR: 9.81e-03\n",
      "Step 12000 | Loss: 1.1421 | LR: 9.81e-03\n",
      "Step 12000 | Loss: 1.1421 | LR: 9.81e-03\n",
      "Step 12500 | Loss: 1.1365 | LR: 8.81e-03\n",
      "Step 12500 | Loss: 1.1365 | LR: 8.81e-03\n",
      "Step 12500 | Loss: 1.1365 | LR: 8.81e-03\n",
      "Step 12500 | Loss: 1.1365 | LR: 8.81e-03\n",
      "Step 12500 | Loss: 1.1364 | LR: 8.81e-03\n",
      "Step 12500 | Loss: 1.1364 | LR: 8.81e-03\n",
      "Step 12500 | Loss: 1.1364 | LR: 8.81e-03\n",
      "Step 12500 | Loss: 1.1364 | LR: 8.81e-03\n",
      "Step 13000 | Loss: 1.1265 | LR: 7.80e-03\n",
      "Step 13000 | Loss: 1.1265 | LR: 7.80e-03\n",
      "Step 13000 | Loss: 1.1266 | LR: 7.80e-03\n",
      "Step 13000 | Loss: 1.1266 | LR: 7.80e-03\n",
      "Step 13000 | Loss: 1.1266 | LR: 7.80e-03\n",
      "Step 13000 | Loss: 1.1266 | LR: 7.80e-03\n",
      "Step 13000 | Loss: 1.1266 | LR: 7.80e-03\n",
      "Step 13000 | Loss: 1.1266 | LR: 7.80e-03\n",
      "Step 13500 | Loss: 1.1159 | LR: 6.79e-03\n",
      "Step 13500 | Loss: 1.1159 | LR: 6.79e-03\n",
      "Step 13500 | Loss: 1.1159 | LR: 6.79e-03\n",
      "Step 13500 | Loss: 1.1159 | LR: 6.79e-03\n",
      "Step 13500 | Loss: 1.1159 | LR: 6.79e-03\n",
      "Step 13500 | Loss: 1.1159 | LR: 6.79e-03\n",
      "Step 13500 | Loss: 1.1159 | LR: 6.79e-03\n",
      "Step 13500 | Loss: 1.1159 | LR: 6.79e-03\n",
      "Step 14000 | Loss: 1.1046 | LR: 5.78e-03\n",
      "Step 14000 | Loss: 1.1046 | LR: 5.78e-03\n",
      "Step 14000 | Loss: 1.1046 | LR: 5.78e-03\n",
      "Step 14000 | Loss: 1.1046 | LR: 5.78e-03\n",
      "Step 14000 | Loss: 1.1046 | LR: 5.78e-03\n",
      "Step 14000 | Loss: 1.1046 | LR: 5.78e-03\n",
      "Step 14000 | Loss: 1.1046 | LR: 5.78e-03\n",
      "Step 14000 | Loss: 1.1046 | LR: 5.78e-03\n",
      "Step 14500 | Loss: 1.0921 | LR: 4.77e-03\n",
      "Step 14500 | Loss: 1.0921 | LR: 4.77e-03\n",
      "Step 14500 | Loss: 1.0921 | LR: 4.77e-03\n",
      "Step 14500 | Loss: 1.0921 | LR: 4.77e-03\n",
      "Step 14500 | Loss: 1.0921 | LR: 4.77e-03\n",
      "Step 14500 | Loss: 1.0921 | LR: 4.77e-03\n",
      "Step 14500 | Loss: 1.0921 | LR: 4.77e-03\n",
      "Step 14500 | Loss: 1.0921 | LR: 4.77e-03\n",
      "Step 15000 | Loss: 1.0797 | LR: 3.76e-03\n",
      "Step 15000 | Loss: 1.0797 | LR: 3.76e-03\n",
      "Step 15000 | Loss: 1.0796 | LR: 3.76e-03\n",
      "Step 15000 | Loss: 1.0796 | LR: 3.76e-03\n",
      "Step 15000 | Loss: 1.0796 | LR: 3.76e-03\n",
      "Step 15000 | Loss: 1.0796 | LR: 3.76e-03\n",
      "Step 15000 | Loss: 1.0796 | LR: 3.76e-03\n",
      "Step 15000 | Loss: 1.0796 | LR: 3.76e-03\n",
      "Step 15500 | Loss: 1.0673 | LR: 2.75e-03\n",
      "Step 15500 | Loss: 1.0673 | LR: 2.75e-03\n",
      "Step 15500 | Loss: 1.0673 | LR: 2.75e-03\n",
      "Step 15500 | Loss: 1.0673 | LR: 2.75e-03\n",
      "Step 15500 | Loss: 1.0673 | LR: 2.75e-03\n",
      "Step 15500 | Loss: 1.0673 | LR: 2.75e-03\n",
      "Step 15500 | Loss: 1.0673 | LR: 2.75e-03\n",
      "Step 15500 | Loss: 1.0673 | LR: 2.75e-03\n",
      "Step 16000 | Loss: 1.0542 | LR: 1.74e-03\n",
      "Step 16000 | Loss: 1.0542 | LR: 1.74e-03\n",
      "Step 16000 | Loss: 1.0541 | LR: 1.74e-03\n",
      "Step 16000 | Loss: 1.0541 | LR: 1.74e-03\n",
      "Step 16000 | Loss: 1.0542 | LR: 1.74e-03\n",
      "Step 16000 | Loss: 1.0542 | LR: 1.74e-03\n",
      "Step 16000 | Loss: 1.0541 | LR: 1.74e-03\n",
      "Step 16000 | Loss: 1.0541 | LR: 1.74e-03\n",
      "Step 16500 | Loss: 1.0421 | LR: 7.31e-04\n",
      "Step 16500 | Loss: 1.0421 | LR: 7.31e-04\n",
      "Step 16500 | Loss: 1.0421 | LR: 7.31e-04\n",
      "Step 16500 | Loss: 1.0421 | LR: 7.31e-04\n",
      "Step 16500 | Loss: 1.0421 | LR: 7.31e-04\n",
      "Step 16500 | Loss: 1.0421 | LR: 7.31e-04\n",
      "Step 16500 | Loss: 1.0421 | LR: 7.31e-04\n",
      "Step 16500 | Loss: 1.0421 | LR: 7.31e-04\n",
      "\n",
      "Validating epoch 3...\n",
      "\n",
      "Validating epoch 3...\n",
      "Epoch 3: Train Loss=1.0334, Val Loss=1.8777, R1=0.1741, R2=0.0507, RL=0.1320, BLEU=8.01, Time=293.2min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1241/5.04 HI=0.1411/8.52 PA=0.1307/16.73 \n",
      "\n",
      "Epoch 3: Train Loss=1.0334, Val Loss=1.8777, R1=0.1741, R2=0.0507, RL=0.1320, BLEU=8.01, Time=293.2min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1241/5.04 HI=0.1411/8.52 PA=0.1307/16.73 \n",
      "\n",
      "New best model saved! rougeL: 0.1320 (epoch 2)\n",
      "New best model saved! rougeL: 0.1320 (epoch 2)\n",
      "No improvement. Patience: 1/5\n",
      "\n",
      "Training completed! Best rougeL: 0.1320 at epoch 2\n",
      "\n",
      "\n",
      "âœ… Phase 3: Medium completed!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š Phase 4: Long\n",
      "   Max Input Length: 512\n",
      "   Max Target Length: 128\n",
      "   Epochs: 2\n",
      "======================================================================\n",
      "\n",
      "No improvement. Patience: 1/5\n",
      "\n",
      "Training completed! Best rougeL: 0.1320 at epoch 2\n",
      "\n",
      "\n",
      "âœ… Phase 3: Medium completed!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“š Phase 4: Long\n",
      "   Max Input Length: 512\n",
      "   Max Target Length: 128\n",
      "   Epochs: 2\n",
      "======================================================================\n",
      "\n",
      "Phase 4 Data: 485292 training samples\n",
      "Phase 4 Data: 485292 training samples\n",
      "\n",
      "âœ“ Using Muon optimizer with LR=3.00e-02\n",
      "  - Muon params: 307 (2D+ weights)\n",
      "  - AdamW params: 283 (embeddings, biases, norms)\n",
      "\n",
      "\n",
      "âš¡ Training in full FP32 precision (no AMP) for maximum stability\n",
      "\n",
      "Training: 2 epochs, 15165 steps, batch size 64\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 1/2\n",
      "============================================================\n",
      "\n",
      "âœ“ Using Muon optimizer with LR=3.00e-02\n",
      "  - Muon params: 307 (2D+ weights)\n",
      "  - AdamW params: 283 (embeddings, biases, norms)\n",
      "\n",
      "\n",
      "âš¡ Training in full FP32 precision (no AMP) for maximum stability\n",
      "\n",
      "Training: 2 epochs, 15165 steps, batch size 64\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 1/2\n",
      "============================================================\n",
      "Step 500 | Loss: 0.9893 | LR: 7.50e-03\n",
      "Step 500 | Loss: 0.9893 | LR: 7.50e-03\n",
      "Step 500 | Loss: 0.9892 | LR: 7.50e-03\n",
      "Step 500 | Loss: 0.9892 | LR: 7.50e-03\n",
      "Step 500 | Loss: 0.9892 | LR: 7.50e-03\n",
      "Step 500 | Loss: 0.9892 | LR: 7.50e-03\n",
      "Step 500 | Loss: 0.9892 | LR: 7.50e-03\n",
      "Step 500 | Loss: 0.9892 | LR: 7.50e-03\n",
      "Step 1000 | Loss: 0.9779 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 0.9779 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 0.9778 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 0.9778 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 0.9779 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 0.9779 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 0.9779 | LR: 1.50e-02\n",
      "Step 1000 | Loss: 0.9779 | LR: 1.50e-02\n",
      "Step 1500 | Loss: 1.0175 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.0175 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.0175 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.0175 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.0175 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.0175 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.0176 | LR: 2.25e-02\n",
      "Step 1500 | Loss: 1.0176 | LR: 2.25e-02\n",
      "Step 2000 | Loss: 1.0755 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.0755 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.0755 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.0755 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.0756 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.0756 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.0756 | LR: 3.00e-02\n",
      "Step 2000 | Loss: 1.0756 | LR: 3.00e-02\n",
      "Step 2500 | Loss: 1.1224 | LR: 2.89e-02\n",
      "Step 2500 | Loss: 1.1224 | LR: 2.89e-02\n",
      "Step 2500 | Loss: 1.1224 | LR: 2.89e-02\n",
      "Step 2500 | Loss: 1.1224 | LR: 2.89e-02\n",
      "Step 2500 | Loss: 1.1224 | LR: 2.89e-02\n",
      "Step 2500 | Loss: 1.1224 | LR: 2.89e-02\n",
      "Step 2500 | Loss: 1.1224 | LR: 2.89e-02\n",
      "Step 2500 | Loss: 1.1224 | LR: 2.89e-02\n",
      "Step 3000 | Loss: 1.1487 | LR: 2.77e-02\n",
      "Step 3000 | Loss: 1.1487 | LR: 2.77e-02\n",
      "Step 3000 | Loss: 1.1487 | LR: 2.77e-02\n",
      "Step 3000 | Loss: 1.1487 | LR: 2.77e-02\n",
      "Step 3000 | Loss: 1.1487 | LR: 2.77e-02\n",
      "Step 3000 | Loss: 1.1487 | LR: 2.77e-02\n",
      "Step 3000 | Loss: 1.1487 | LR: 2.77e-02\n",
      "Step 3000 | Loss: 1.1487 | LR: 2.77e-02\n",
      "Step 3500 | Loss: 1.1635 | LR: 2.66e-02\n",
      "Step 3500 | Loss: 1.1635 | LR: 2.66e-02\n",
      "Step 3500 | Loss: 1.1635 | LR: 2.66e-02\n",
      "Step 3500 | Loss: 1.1635 | LR: 2.66e-02\n",
      "Step 3500 | Loss: 1.1635 | LR: 2.66e-02\n",
      "Step 3500 | Loss: 1.1635 | LR: 2.66e-02\n",
      "Step 3500 | Loss: 1.1635 | LR: 2.66e-02\n",
      "Step 3500 | Loss: 1.1635 | LR: 2.66e-02\n",
      "Step 4000 | Loss: 1.1706 | LR: 2.54e-02\n",
      "Step 4000 | Loss: 1.1706 | LR: 2.54e-02\n",
      "Step 4000 | Loss: 1.1706 | LR: 2.54e-02\n",
      "Step 4000 | Loss: 1.1706 | LR: 2.54e-02\n",
      "Step 4000 | Loss: 1.1706 | LR: 2.54e-02\n",
      "Step 4000 | Loss: 1.1706 | LR: 2.54e-02\n",
      "Step 4000 | Loss: 1.1706 | LR: 2.54e-02\n",
      "Step 4000 | Loss: 1.1706 | LR: 2.54e-02\n",
      "Step 4500 | Loss: 1.1727 | LR: 2.43e-02\n",
      "Step 4500 | Loss: 1.1727 | LR: 2.43e-02\n",
      "Step 4500 | Loss: 1.1727 | LR: 2.43e-02\n",
      "Step 4500 | Loss: 1.1727 | LR: 2.43e-02\n",
      "Step 4500 | Loss: 1.1727 | LR: 2.43e-02\n",
      "Step 4500 | Loss: 1.1727 | LR: 2.43e-02\n",
      "Step 4500 | Loss: 1.1727 | LR: 2.43e-02\n",
      "Step 4500 | Loss: 1.1727 | LR: 2.43e-02\n",
      "Step 5000 | Loss: 1.1725 | LR: 2.32e-02\n",
      "Step 5000 | Loss: 1.1725 | LR: 2.32e-02\n",
      "Step 5000 | Loss: 1.1725 | LR: 2.32e-02\n",
      "Step 5000 | Loss: 1.1725 | LR: 2.32e-02\n",
      "Step 5000 | Loss: 1.1725 | LR: 2.32e-02\n",
      "Step 5000 | Loss: 1.1725 | LR: 2.32e-02\n",
      "Step 5000 | Loss: 1.1725 | LR: 2.32e-02\n",
      "Step 5000 | Loss: 1.1725 | LR: 2.32e-02\n",
      "Step 5500 | Loss: 1.1700 | LR: 2.20e-02\n",
      "Step 5500 | Loss: 1.1700 | LR: 2.20e-02\n",
      "Step 5500 | Loss: 1.1700 | LR: 2.20e-02\n",
      "Step 5500 | Loss: 1.1700 | LR: 2.20e-02\n",
      "Step 5500 | Loss: 1.1700 | LR: 2.20e-02\n",
      "Step 5500 | Loss: 1.1700 | LR: 2.20e-02\n",
      "Step 5500 | Loss: 1.1701 | LR: 2.20e-02\n",
      "Step 5500 | Loss: 1.1701 | LR: 2.20e-02\n",
      "Step 6000 | Loss: 1.1662 | LR: 2.09e-02\n",
      "Step 6000 | Loss: 1.1662 | LR: 2.09e-02\n",
      "Step 6000 | Loss: 1.1662 | LR: 2.09e-02\n",
      "Step 6000 | Loss: 1.1662 | LR: 2.09e-02\n",
      "Step 6000 | Loss: 1.1662 | LR: 2.09e-02\n",
      "Step 6000 | Loss: 1.1662 | LR: 2.09e-02\n",
      "Step 6000 | Loss: 1.1662 | LR: 2.09e-02\n",
      "Step 6000 | Loss: 1.1662 | LR: 2.09e-02\n",
      "Step 6500 | Loss: 1.1618 | LR: 1.97e-02\n",
      "Step 6500 | Loss: 1.1618 | LR: 1.97e-02\n",
      "Step 6500 | Loss: 1.1618 | LR: 1.97e-02\n",
      "Step 6500 | Loss: 1.1618 | LR: 1.97e-02\n",
      "Step 6500 | Loss: 1.1618 | LR: 1.97e-02\n",
      "Step 6500 | Loss: 1.1618 | LR: 1.97e-02\n",
      "Step 6500 | Loss: 1.1618 | LR: 1.97e-02\n",
      "Step 6500 | Loss: 1.1618 | LR: 1.97e-02\n",
      "Step 7000 | Loss: 1.1568 | LR: 1.86e-02\n",
      "Step 7000 | Loss: 1.1568 | LR: 1.86e-02\n",
      "Step 7000 | Loss: 1.1568 | LR: 1.86e-02\n",
      "Step 7000 | Loss: 1.1568 | LR: 1.86e-02\n",
      "Step 7000 | Loss: 1.1568 | LR: 1.86e-02\n",
      "Step 7000 | Loss: 1.1568 | LR: 1.86e-02\n",
      "Step 7000 | Loss: 1.1568 | LR: 1.86e-02\n",
      "Step 7000 | Loss: 1.1568 | LR: 1.86e-02\n",
      "Step 7500 | Loss: 1.1511 | LR: 1.75e-02\n",
      "Step 7500 | Loss: 1.1511 | LR: 1.75e-02\n",
      "Step 7500 | Loss: 1.1511 | LR: 1.75e-02\n",
      "Step 7500 | Loss: 1.1511 | LR: 1.75e-02\n",
      "Step 7500 | Loss: 1.1511 | LR: 1.75e-02\n",
      "Step 7500 | Loss: 1.1511 | LR: 1.75e-02\n",
      "Step 7500 | Loss: 1.1512 | LR: 1.75e-02\n",
      "Step 7500 | Loss: 1.1512 | LR: 1.75e-02\n",
      "\n",
      "Validating epoch 1...\n",
      "\n",
      "Validating epoch 1...\n",
      "Epoch 1: Train Loss=1.1503, Val Loss=1.3314, R1=0.1598, R2=0.0381, RL=0.1168, BLEU=4.92, Time=145.6min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1071/2.85 HI=0.1250/35.42 PA=0.1182/21.58 \n",
      "\n",
      "Epoch 1: Train Loss=1.1503, Val Loss=1.3314, R1=0.1598, R2=0.0381, RL=0.1168, BLEU=4.92, Time=145.6min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1071/2.85 HI=0.1250/35.42 PA=0.1182/21.58 \n",
      "\n",
      "New best model saved! rougeL: 0.1168 (epoch 0)\n",
      "New best model saved! rougeL: 0.1168 (epoch 0)\n",
      "\n",
      "============================================================\n",
      "Epoch 2/2\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Epoch 2/2\n",
      "============================================================\n",
      "Step 8000 | Loss: 1.0208 | LR: 1.63e-02\n",
      "Step 8000 | Loss: 1.0208 | LR: 1.63e-02\n",
      "Step 8000 | Loss: 1.0208 | LR: 1.63e-02\n",
      "Step 8000 | Loss: 1.0208 | LR: 1.63e-02\n",
      "Step 8000 | Loss: 1.0209 | LR: 1.63e-02\n",
      "Step 8000 | Loss: 1.0209 | LR: 1.63e-02\n",
      "Step 8000 | Loss: 1.0210 | LR: 1.63e-02\n",
      "Step 8000 | Loss: 1.0210 | LR: 1.63e-02\n",
      "Step 8500 | Loss: 1.0155 | LR: 1.52e-02\n",
      "Step 8500 | Loss: 1.0155 | LR: 1.52e-02\n",
      "Step 8500 | Loss: 1.0155 | LR: 1.52e-02\n",
      "Step 8500 | Loss: 1.0155 | LR: 1.52e-02\n",
      "Step 8500 | Loss: 1.0155 | LR: 1.52e-02\n",
      "Step 8500 | Loss: 1.0155 | LR: 1.52e-02\n",
      "Step 8500 | Loss: 1.0154 | LR: 1.52e-02\n",
      "Step 8500 | Loss: 1.0154 | LR: 1.52e-02\n",
      "Step 9000 | Loss: 1.0097 | LR: 1.40e-02\n",
      "Step 9000 | Loss: 1.0097 | LR: 1.40e-02\n",
      "Step 9000 | Loss: 1.0097 | LR: 1.40e-02\n",
      "Step 9000 | Loss: 1.0097 | LR: 1.40e-02\n",
      "Step 9000 | Loss: 1.0097 | LR: 1.40e-02\n",
      "Step 9000 | Loss: 1.0097 | LR: 1.40e-02\n",
      "Step 9000 | Loss: 1.0096 | LR: 1.40e-02\n",
      "Step 9000 | Loss: 1.0096 | LR: 1.40e-02\n",
      "Step 9500 | Loss: 1.0025 | LR: 1.29e-02\n",
      "Step 9500 | Loss: 1.0025 | LR: 1.29e-02\n",
      "Step 9500 | Loss: 1.0024 | LR: 1.29e-02\n",
      "Step 9500 | Loss: 1.0024 | LR: 1.29e-02\n",
      "Step 9500 | Loss: 1.0024 | LR: 1.29e-02\n",
      "Step 9500 | Loss: 1.0024 | LR: 1.29e-02\n",
      "Step 9500 | Loss: 1.0024 | LR: 1.29e-02\n",
      "Step 9500 | Loss: 1.0024 | LR: 1.29e-02\n",
      "Step 10000 | Loss: 0.9939 | LR: 1.18e-02\n",
      "Step 10000 | Loss: 0.9939 | LR: 1.18e-02\n",
      "Step 10000 | Loss: 0.9939 | LR: 1.18e-02\n",
      "Step 10000 | Loss: 0.9939 | LR: 1.18e-02\n",
      "Step 10000 | Loss: 0.9939 | LR: 1.18e-02\n",
      "Step 10000 | Loss: 0.9939 | LR: 1.18e-02\n",
      "Step 10000 | Loss: 0.9939 | LR: 1.18e-02\n",
      "Step 10000 | Loss: 0.9939 | LR: 1.18e-02\n",
      "Step 10500 | Loss: 0.9858 | LR: 1.06e-02\n",
      "Step 10500 | Loss: 0.9858 | LR: 1.06e-02\n",
      "Step 10500 | Loss: 0.9858 | LR: 1.06e-02\n",
      "Step 10500 | Loss: 0.9858 | LR: 1.06e-02\n",
      "Step 10500 | Loss: 0.9858 | LR: 1.06e-02\n",
      "Step 10500 | Loss: 0.9858 | LR: 1.06e-02\n",
      "Step 10500 | Loss: 0.9858 | LR: 1.06e-02\n",
      "Step 10500 | Loss: 0.9858 | LR: 1.06e-02\n",
      "Step 11000 | Loss: 0.9771 | LR: 9.49e-03\n",
      "Step 11000 | Loss: 0.9771 | LR: 9.49e-03\n",
      "Step 11000 | Loss: 0.9771 | LR: 9.49e-03\n",
      "Step 11000 | Loss: 0.9771 | LR: 9.49e-03\n",
      "Step 11000 | Loss: 0.9771 | LR: 9.49e-03\n",
      "Step 11000 | Loss: 0.9771 | LR: 9.49e-03\n",
      "Step 11000 | Loss: 0.9771 | LR: 9.49e-03\n",
      "Step 11000 | Loss: 0.9771 | LR: 9.49e-03\n",
      "Step 11500 | Loss: 0.9684 | LR: 8.35e-03\n",
      "Step 11500 | Loss: 0.9684 | LR: 8.35e-03\n",
      "Step 11500 | Loss: 0.9684 | LR: 8.35e-03\n",
      "Step 11500 | Loss: 0.9684 | LR: 8.35e-03\n",
      "Step 11500 | Loss: 0.9684 | LR: 8.35e-03\n",
      "Step 11500 | Loss: 0.9684 | LR: 8.35e-03\n",
      "Step 11500 | Loss: 0.9684 | LR: 8.35e-03\n",
      "Step 11500 | Loss: 0.9684 | LR: 8.35e-03\n",
      "Step 12000 | Loss: 0.9596 | LR: 7.21e-03\n",
      "Step 12000 | Loss: 0.9596 | LR: 7.21e-03\n",
      "Step 12000 | Loss: 0.9596 | LR: 7.21e-03\n",
      "Step 12000 | Loss: 0.9596 | LR: 7.21e-03\n",
      "Step 12000 | Loss: 0.9596 | LR: 7.21e-03\n",
      "Step 12000 | Loss: 0.9596 | LR: 7.21e-03\n",
      "Step 12000 | Loss: 0.9596 | LR: 7.21e-03\n",
      "Step 12000 | Loss: 0.9596 | LR: 7.21e-03\n",
      "Step 12500 | Loss: 0.9505 | LR: 6.07e-03\n",
      "Step 12500 | Loss: 0.9505 | LR: 6.07e-03\n",
      "Step 12500 | Loss: 0.9505 | LR: 6.07e-03\n",
      "Step 12500 | Loss: 0.9505 | LR: 6.07e-03\n",
      "Step 12500 | Loss: 0.9505 | LR: 6.07e-03\n",
      "Step 12500 | Loss: 0.9505 | LR: 6.07e-03\n",
      "Step 12500 | Loss: 0.9505 | LR: 6.07e-03\n",
      "Step 12500 | Loss: 0.9505 | LR: 6.07e-03\n",
      "Step 13000 | Loss: 0.9406 | LR: 4.93e-03\n",
      "Step 13000 | Loss: 0.9406 | LR: 4.93e-03\n",
      "Step 13000 | Loss: 0.9406 | LR: 4.93e-03\n",
      "Step 13000 | Loss: 0.9406 | LR: 4.93e-03\n",
      "Step 13000 | Loss: 0.9406 | LR: 4.93e-03\n",
      "Step 13000 | Loss: 0.9406 | LR: 4.93e-03\n",
      "Step 13000 | Loss: 0.9406 | LR: 4.93e-03\n",
      "Step 13000 | Loss: 0.9406 | LR: 4.93e-03\n",
      "Step 13500 | Loss: 0.9305 | LR: 3.79e-03\n",
      "Step 13500 | Loss: 0.9305 | LR: 3.79e-03\n",
      "Step 13500 | Loss: 0.9305 | LR: 3.79e-03\n",
      "Step 13500 | Loss: 0.9305 | LR: 3.79e-03\n",
      "Step 13500 | Loss: 0.9305 | LR: 3.79e-03\n",
      "Step 13500 | Loss: 0.9305 | LR: 3.79e-03\n",
      "Step 13500 | Loss: 0.9305 | LR: 3.79e-03\n",
      "Step 13500 | Loss: 0.9305 | LR: 3.79e-03\n",
      "Step 14000 | Loss: 0.9206 | LR: 2.65e-03\n",
      "Step 14000 | Loss: 0.9206 | LR: 2.65e-03\n",
      "Step 14000 | Loss: 0.9206 | LR: 2.65e-03\n",
      "Step 14000 | Loss: 0.9206 | LR: 2.65e-03\n",
      "Step 14000 | Loss: 0.9206 | LR: 2.65e-03\n",
      "Step 14000 | Loss: 0.9206 | LR: 2.65e-03\n",
      "Step 14000 | Loss: 0.9206 | LR: 2.65e-03\n",
      "Step 14000 | Loss: 0.9206 | LR: 2.65e-03\n",
      "Step 14500 | Loss: 0.9110 | LR: 1.52e-03\n",
      "Step 14500 | Loss: 0.9110 | LR: 1.52e-03\n",
      "Step 14500 | Loss: 0.9110 | LR: 1.52e-03\n",
      "Step 14500 | Loss: 0.9110 | LR: 1.52e-03\n",
      "Step 14500 | Loss: 0.9110 | LR: 1.52e-03\n",
      "Step 14500 | Loss: 0.9110 | LR: 1.52e-03\n",
      "Step 14500 | Loss: 0.9110 | LR: 1.52e-03\n",
      "Step 14500 | Loss: 0.9110 | LR: 1.52e-03\n",
      "Step 15000 | Loss: 0.9013 | LR: 3.76e-04\n",
      "Step 15000 | Loss: 0.9013 | LR: 3.76e-04\n",
      "Step 15000 | Loss: 0.9013 | LR: 3.76e-04\n",
      "Step 15000 | Loss: 0.9013 | LR: 3.76e-04\n",
      "Step 15000 | Loss: 0.9013 | LR: 3.76e-04\n",
      "Step 15000 | Loss: 0.9013 | LR: 3.76e-04\n",
      "Step 15000 | Loss: 0.9013 | LR: 3.76e-04\n",
      "Step 15000 | Loss: 0.9013 | LR: 3.76e-04\n",
      "\n",
      "Validating epoch 2...\n",
      "\n",
      "Validating epoch 2...\n",
      "Epoch 2: Train Loss=0.8987, Val Loss=1.2999, R1=0.1751, R2=0.0476, RL=0.1323, BLEU=3.11, Time=291.0min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1305/3.00 HI=0.1308/29.82 PA=0.1354/52.95 \n",
      "\n",
      "Epoch 2: Train Loss=0.8987, Val Loss=1.2999, R1=0.1751, R2=0.0476, RL=0.1323, BLEU=3.11, Time=291.0min\n",
      "  Per-Language ROUGE-L / BLEU: EN=0.1305/3.00 HI=0.1308/29.82 PA=0.1354/52.95 \n",
      "\n",
      "New best model saved! rougeL: 0.1323 (epoch 1)\n",
      "New best model saved! rougeL: 0.1323 (epoch 1)\n",
      "No improvement. Patience: 1/5\n",
      "\n",
      "Training completed! Best rougeL: 0.1323 at epoch 1\n",
      "\n",
      "\n",
      "âœ… Phase 4: Long completed!\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ CURRICULUM LEARNING COMPLETED\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "âœ“ TRAINING COMPLETED!\n",
      "======================================================================\n",
      "Total training time: 4.85 hours\n",
      "Final train loss: 0.8987\n",
      "Final val loss: 1.2999\n",
      "Final ROUGE-L: 0.1323\n",
      "======================================================================\n",
      "\n",
      "No improvement. Patience: 1/5\n",
      "\n",
      "Training completed! Best rougeL: 0.1323 at epoch 1\n",
      "\n",
      "\n",
      "âœ… Phase 4: Long completed!\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ CURRICULUM LEARNING COMPLETED\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "âœ“ TRAINING COMPLETED!\n",
      "======================================================================\n",
      "Total training time: 4.85 hours\n",
      "Final train loss: 0.8987\n",
      "Final val loss: 1.2999\n",
      "Final ROUGE-L: 0.1323\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== TRAIN MODEL WITH OPTIMAL HYPERPARAMETERS =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING MODEL WITH OPTIMIZED HYPERPARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nOptimal Configuration:\")\n",
    "print(f\"  Learning Rate: {config.learning_rate:.2e}\")\n",
    "print(f\"  Batch Size: {config.batch_size}\")\n",
    "print(f\"  Gradient Accumulation: {config.gradient_accumulation_steps}\")\n",
    "print(f\"  Effective Batch Size: {config.batch_size * config.gradient_accumulation_steps}\")\n",
    "print(f\"  Epochs: {config.num_epochs}\")\n",
    "print(f\"  Warmup Steps: {config.warmup_steps}\")\n",
    "print(f\"  Weight Decay: {config.weight_decay}\")\n",
    "print(f\"  Gradient Clip: {config.gradient_clip_val}\")\n",
    "print(f\"  Aux Loss Weight: {config.aux_loss_weight_end}\")\n",
    "print(f\"  Expert Dropout: {config.expert_dropout}\")\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Training Samples: {len(train_data)}\")\n",
    "print(f\"  Validation Samples: {len(val_data)}\")\n",
    "print(f\"  Test Samples: {len(test_data)}\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Train with curriculum learning and optimal hyperparameters\n",
    "training_history = train_with_curriculum(\n",
    "    model, \n",
    "    train_data, \n",
    "    val_data, \n",
    "    tokenizer, \n",
    "    use_muon=True, \n",
    "    lr=config.learning_rate\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ“ TRAINING COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total training time: {training_history['training_time']/3600:.2f} hours\")\n",
    "print(f\"Final train loss: {training_history['train_losses'][-1]:.4f}\")\n",
    "print(f\"Final val loss: {training_history['val_losses'][-1]:.4f}\")\n",
    "print(f\"Final ROUGE-L: {training_history['val_rouge_scores'][-1]['rougeL']:.4f}\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "014c2b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EVALUATING ON TEST SET\n",
      "======================================================================\n",
      "\n",
      "Starting evaluation on test set...\n",
      "Processed 10/1338 batches\n",
      "Processed 10/1338 batches\n",
      "Processed 20/1338 batches\n",
      "Processed 20/1338 batches\n",
      "Processed 30/1338 batches\n",
      "Processed 30/1338 batches\n",
      "Processed 40/1338 batches\n",
      "Processed 40/1338 batches\n",
      "Processed 50/1338 batches\n",
      "Processed 50/1338 batches\n",
      "Processed 60/1338 batches\n",
      "Processed 60/1338 batches\n",
      "Processed 70/1338 batches\n",
      "Processed 70/1338 batches\n",
      "Processed 80/1338 batches\n",
      "Processed 80/1338 batches\n",
      "Processed 90/1338 batches\n",
      "Processed 90/1338 batches\n",
      "Processed 100/1338 batches\n",
      "Processed 100/1338 batches\n",
      "Processed 110/1338 batches\n",
      "Processed 110/1338 batches\n",
      "Processed 120/1338 batches\n",
      "Processed 120/1338 batches\n",
      "Processed 130/1338 batches\n",
      "Processed 130/1338 batches\n",
      "Processed 140/1338 batches\n",
      "Processed 140/1338 batches\n",
      "Processed 150/1338 batches\n",
      "Processed 150/1338 batches\n",
      "Processed 160/1338 batches\n",
      "Processed 160/1338 batches\n",
      "Processed 170/1338 batches\n",
      "Processed 170/1338 batches\n",
      "Processed 180/1338 batches\n",
      "Processed 180/1338 batches\n",
      "Processed 190/1338 batches\n",
      "Processed 190/1338 batches\n",
      "Processed 200/1338 batches\n",
      "Processed 200/1338 batches\n",
      "Processed 210/1338 batches\n",
      "Processed 210/1338 batches\n",
      "Processed 220/1338 batches\n",
      "Processed 220/1338 batches\n",
      "Processed 230/1338 batches\n",
      "Processed 230/1338 batches\n",
      "Processed 240/1338 batches\n",
      "Processed 240/1338 batches\n",
      "Processed 250/1338 batches\n",
      "Processed 250/1338 batches\n",
      "Processed 260/1338 batches\n",
      "Processed 260/1338 batches\n",
      "Processed 270/1338 batches\n",
      "Processed 270/1338 batches\n",
      "Processed 280/1338 batches\n",
      "Processed 280/1338 batches\n",
      "Processed 290/1338 batches\n",
      "Processed 290/1338 batches\n",
      "Processed 300/1338 batches\n",
      "Processed 300/1338 batches\n",
      "Processed 310/1338 batches\n",
      "Processed 310/1338 batches\n",
      "Processed 320/1338 batches\n",
      "Processed 320/1338 batches\n",
      "Processed 330/1338 batches\n",
      "Processed 330/1338 batches\n",
      "Processed 340/1338 batches\n",
      "Processed 340/1338 batches\n",
      "Processed 350/1338 batches\n",
      "Processed 350/1338 batches\n",
      "Processed 360/1338 batches\n",
      "Processed 360/1338 batches\n",
      "Processed 370/1338 batches\n",
      "Processed 370/1338 batches\n",
      "Processed 380/1338 batches\n",
      "Processed 380/1338 batches\n",
      "Processed 390/1338 batches\n",
      "Processed 390/1338 batches\n",
      "Processed 400/1338 batches\n",
      "Processed 400/1338 batches\n",
      "Processed 410/1338 batches\n",
      "Processed 410/1338 batches\n",
      "Processed 420/1338 batches\n",
      "Processed 420/1338 batches\n",
      "Processed 430/1338 batches\n",
      "Processed 430/1338 batches\n",
      "Processed 440/1338 batches\n",
      "Processed 440/1338 batches\n",
      "Processed 450/1338 batches\n",
      "Processed 450/1338 batches\n",
      "Processed 460/1338 batches\n",
      "Processed 460/1338 batches\n",
      "Processed 470/1338 batches\n",
      "Processed 470/1338 batches\n",
      "Processed 480/1338 batches\n",
      "Processed 480/1338 batches\n",
      "Processed 490/1338 batches\n",
      "Processed 490/1338 batches\n",
      "Processed 500/1338 batches\n",
      "Processed 500/1338 batches\n",
      "Processed 510/1338 batches\n",
      "Processed 510/1338 batches\n",
      "Processed 520/1338 batches\n",
      "Processed 520/1338 batches\n",
      "Processed 530/1338 batches\n",
      "Processed 530/1338 batches\n",
      "Processed 540/1338 batches\n",
      "Processed 540/1338 batches\n",
      "Processed 550/1338 batches\n",
      "Processed 550/1338 batches\n",
      "Processed 560/1338 batches\n",
      "Processed 560/1338 batches\n",
      "Processed 570/1338 batches\n",
      "Processed 570/1338 batches\n",
      "Processed 580/1338 batches\n",
      "Processed 580/1338 batches\n",
      "Processed 590/1338 batches\n",
      "Processed 590/1338 batches\n",
      "Processed 600/1338 batches\n",
      "Processed 600/1338 batches\n",
      "Processed 610/1338 batches\n",
      "Processed 610/1338 batches\n",
      "Processed 620/1338 batches\n",
      "Processed 620/1338 batches\n",
      "Processed 630/1338 batches\n",
      "Processed 630/1338 batches\n",
      "Processed 640/1338 batches\n",
      "Processed 640/1338 batches\n",
      "Processed 650/1338 batches\n",
      "Processed 650/1338 batches\n",
      "Processed 660/1338 batches\n",
      "Processed 660/1338 batches\n",
      "Processed 670/1338 batches\n",
      "Processed 670/1338 batches\n",
      "Processed 680/1338 batches\n",
      "Processed 680/1338 batches\n",
      "Processed 690/1338 batches\n",
      "Processed 690/1338 batches\n",
      "Processed 700/1338 batches\n",
      "Processed 700/1338 batches\n",
      "Processed 710/1338 batches\n",
      "Processed 710/1338 batches\n",
      "Processed 720/1338 batches\n",
      "Processed 720/1338 batches\n",
      "Processed 730/1338 batches\n",
      "Processed 730/1338 batches\n",
      "Processed 740/1338 batches\n",
      "Processed 740/1338 batches\n",
      "Processed 750/1338 batches\n",
      "Processed 750/1338 batches\n",
      "Processed 760/1338 batches\n",
      "Processed 760/1338 batches\n",
      "Processed 770/1338 batches\n",
      "Processed 770/1338 batches\n",
      "Processed 780/1338 batches\n",
      "Processed 780/1338 batches\n",
      "Processed 790/1338 batches\n",
      "Processed 790/1338 batches\n",
      "Processed 800/1338 batches\n",
      "Processed 800/1338 batches\n",
      "Processed 810/1338 batches\n",
      "Processed 810/1338 batches\n",
      "Processed 820/1338 batches\n",
      "Processed 820/1338 batches\n",
      "Processed 830/1338 batches\n",
      "Processed 830/1338 batches\n",
      "Processed 840/1338 batches\n",
      "Processed 840/1338 batches\n",
      "Processed 850/1338 batches\n",
      "Processed 850/1338 batches\n",
      "Processed 860/1338 batches\n",
      "Processed 860/1338 batches\n",
      "Processed 870/1338 batches\n",
      "Processed 870/1338 batches\n",
      "Processed 880/1338 batches\n",
      "Processed 880/1338 batches\n",
      "Processed 890/1338 batches\n",
      "Processed 890/1338 batches\n",
      "Processed 900/1338 batches\n",
      "Processed 900/1338 batches\n",
      "Processed 910/1338 batches\n",
      "Processed 910/1338 batches\n",
      "Processed 920/1338 batches\n",
      "Processed 920/1338 batches\n",
      "Processed 930/1338 batches\n",
      "Processed 930/1338 batches\n",
      "Processed 940/1338 batches\n",
      "Processed 940/1338 batches\n",
      "Processed 950/1338 batches\n",
      "Processed 950/1338 batches\n",
      "Processed 960/1338 batches\n",
      "Processed 960/1338 batches\n",
      "Processed 970/1338 batches\n",
      "Processed 970/1338 batches\n",
      "Processed 980/1338 batches\n",
      "Processed 980/1338 batches\n",
      "Processed 990/1338 batches\n",
      "Processed 990/1338 batches\n",
      "Processed 1000/1338 batches\n",
      "Processed 1000/1338 batches\n",
      "Processed 1010/1338 batches\n",
      "Processed 1010/1338 batches\n",
      "Processed 1020/1338 batches\n",
      "Processed 1020/1338 batches\n",
      "Processed 1030/1338 batches\n",
      "Processed 1030/1338 batches\n",
      "Processed 1040/1338 batches\n",
      "Processed 1040/1338 batches\n",
      "Processed 1050/1338 batches\n",
      "Processed 1050/1338 batches\n",
      "Processed 1060/1338 batches\n",
      "Processed 1060/1338 batches\n",
      "Processed 1070/1338 batches\n",
      "Processed 1070/1338 batches\n",
      "Processed 1080/1338 batches\n",
      "Processed 1080/1338 batches\n",
      "Processed 1090/1338 batches\n",
      "Processed 1090/1338 batches\n",
      "Processed 1100/1338 batches\n",
      "Processed 1100/1338 batches\n",
      "Processed 1110/1338 batches\n",
      "Processed 1110/1338 batches\n",
      "Processed 1120/1338 batches\n",
      "Processed 1120/1338 batches\n",
      "Processed 1130/1338 batches\n",
      "Processed 1130/1338 batches\n",
      "Processed 1140/1338 batches\n",
      "Processed 1140/1338 batches\n",
      "Processed 1150/1338 batches\n",
      "Processed 1150/1338 batches\n",
      "Processed 1160/1338 batches\n",
      "Processed 1160/1338 batches\n",
      "Processed 1170/1338 batches\n",
      "Processed 1170/1338 batches\n",
      "Processed 1180/1338 batches\n",
      "Processed 1180/1338 batches\n",
      "Processed 1190/1338 batches\n",
      "Processed 1190/1338 batches\n",
      "Processed 1200/1338 batches\n",
      "Processed 1200/1338 batches\n",
      "Processed 1210/1338 batches\n",
      "Processed 1210/1338 batches\n",
      "Processed 1220/1338 batches\n",
      "Processed 1220/1338 batches\n",
      "Processed 1230/1338 batches\n",
      "Processed 1230/1338 batches\n",
      "Processed 1240/1338 batches\n",
      "Processed 1240/1338 batches\n",
      "Processed 1250/1338 batches\n",
      "Processed 1250/1338 batches\n",
      "Processed 1260/1338 batches\n",
      "Processed 1260/1338 batches\n",
      "Processed 1270/1338 batches\n",
      "Processed 1270/1338 batches\n",
      "Processed 1280/1338 batches\n",
      "Processed 1280/1338 batches\n",
      "Processed 1290/1338 batches\n",
      "Processed 1290/1338 batches\n",
      "Processed 1300/1338 batches\n",
      "Processed 1300/1338 batches\n",
      "Processed 1310/1338 batches\n",
      "Processed 1310/1338 batches\n",
      "Processed 1320/1338 batches\n",
      "Processed 1320/1338 batches\n",
      "Processed 1330/1338 batches\n",
      "Processed 1330/1338 batches\n",
      "\n",
      "============================================================\n",
      "Overall Test Results:\n",
      "============================================================\n",
      "ROUGE-1: 0.1752\n",
      "ROUGE-2: 0.0501\n",
      "ROUGE-L: 0.1285\n",
      "BLEU:    24.03\n",
      "\n",
      "============================================================\n",
      "Per-Language Test Results:\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Overall Test Results:\n",
      "============================================================\n",
      "ROUGE-1: 0.1752\n",
      "ROUGE-2: 0.0501\n",
      "ROUGE-L: 0.1285\n",
      "BLEU:    24.03\n",
      "\n",
      "============================================================\n",
      "Per-Language Test Results:\n",
      "============================================================\n",
      "\n",
      "EN:\n",
      "  ROUGE-1: 0.3157\n",
      "  ROUGE-2: 0.0928\n",
      "  ROUGE-L: 0.2291\n",
      "  BLEU:    39.45\n",
      "  Samples: 11535\n",
      "\n",
      "EN:\n",
      "  ROUGE-1: 0.3157\n",
      "  ROUGE-2: 0.0928\n",
      "  ROUGE-L: 0.2291\n",
      "  BLEU:    39.45\n",
      "  Samples: 11535\n",
      "\n",
      "HI:\n",
      "  ROUGE-1: 0.0108\n",
      "  ROUGE-2: 0.0003\n",
      "  ROUGE-L: 0.0107\n",
      "  BLEU:    34.19\n",
      "  Samples: 8847\n",
      "\n",
      "PA:\n",
      "  ROUGE-1: 0.0122\n",
      "  ROUGE-2: 0.0000\n",
      "  ROUGE-L: 0.0122\n",
      "  BLEU:    24.03\n",
      "  Samples: 1026\n",
      "============================================================\n",
      "\n",
      "\n",
      "OVERALL TEST RESULTS:\n",
      "  ROUGE-1: 0.1752\n",
      "  ROUGE-2: 0.0501\n",
      "  ROUGE-L: 0.1285\n",
      "\n",
      "PER-LANGUAGE TEST RESULTS:\n",
      "\n",
      "  EN:\n",
      "    ROUGE-1: 0.3157\n",
      "    ROUGE-2: 0.0928\n",
      "    ROUGE-L: 0.2291\n",
      "\n",
      "  HI:\n",
      "    ROUGE-1: 0.0108\n",
      "    ROUGE-2: 0.0003\n",
      "    ROUGE-L: 0.0107\n",
      "\n",
      "  PA:\n",
      "    ROUGE-1: 0.0122\n",
      "    ROUGE-2: 0.0000\n",
      "    ROUGE-L: 0.0122\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "HI:\n",
      "  ROUGE-1: 0.0108\n",
      "  ROUGE-2: 0.0003\n",
      "  ROUGE-L: 0.0107\n",
      "  BLEU:    34.19\n",
      "  Samples: 8847\n",
      "\n",
      "PA:\n",
      "  ROUGE-1: 0.0122\n",
      "  ROUGE-2: 0.0000\n",
      "  ROUGE-L: 0.0122\n",
      "  BLEU:    24.03\n",
      "  Samples: 1026\n",
      "============================================================\n",
      "\n",
      "\n",
      "OVERALL TEST RESULTS:\n",
      "  ROUGE-1: 0.1752\n",
      "  ROUGE-2: 0.0501\n",
      "  ROUGE-L: 0.1285\n",
      "\n",
      "PER-LANGUAGE TEST RESULTS:\n",
      "\n",
      "  EN:\n",
      "    ROUGE-1: 0.3157\n",
      "    ROUGE-2: 0.0928\n",
      "    ROUGE-L: 0.2291\n",
      "\n",
      "  HI:\n",
      "    ROUGE-1: 0.0108\n",
      "    ROUGE-2: 0.0003\n",
      "    ROUGE-L: 0.0107\n",
      "\n",
      "  PA:\n",
      "    ROUGE-1: 0.0122\n",
      "    ROUGE-2: 0.0000\n",
      "    ROUGE-L: 0.0122\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== EVALUATE ON TEST SET =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATING ON TEST SET\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "test_results = evaluate_model(model, test_loader, tokenizer)\n",
    "overall_rouge = test_results[\"overall\"]\n",
    "language_rouge = test_results[\"per_language\"]\n",
    "\n",
    "print(\"\\nOVERALL TEST RESULTS:\")\n",
    "print(f\"  ROUGE-1: {overall_rouge['rouge1']:.4f}\")\n",
    "print(f\"  ROUGE-2: {overall_rouge['rouge2']:.4f}\")\n",
    "print(f\"  ROUGE-L: {overall_rouge['rougeL']:.4f}\")\n",
    "\n",
    "print(\"\\nPER-LANGUAGE TEST RESULTS:\")\n",
    "for lang, scores in language_rouge.items():\n",
    "    print(f\"\\n  {lang.upper()}:\")\n",
    "    print(f\"    ROUGE-1: {scores['rouge1']:.4f}\")\n",
    "    print(f\"    ROUGE-2: {scores['rouge2']:.4f}\")\n",
    "    print(f\"    ROUGE-L: {scores['rougeL']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f08adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as training_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Expert Specialization Analysis\n",
      "============================================================\n",
      "\n",
      "--- Layer 0: base_model.encoder.block.0.layer.1.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 2129246976\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 105726104 calls (  5.0%)\n",
      "  Expert 1 (HI expert): 170046656 calls (  8.0%)\n",
      "  Expert 2 (PU expert): 338087968 calls ( 15.9%)\n",
      "  Expert 3 (shared): 508452800 calls ( 23.9%)\n",
      "  Expert 4 (shared): 62287392 calls (  2.9%)\n",
      "  Expert 5 (shared): 944646080 calls ( 44.4%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 27.7%\n",
      "  âŒ POOR balance (deviation > 20%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 1562004983 tokens\n",
      "  Overflow rate: 136.24%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 1: base_model.encoder.block.1.layer.1.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 2128975104\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 745529344 calls ( 35.0%)\n",
      "  Expert 1 (HI expert): 41605564 calls (  2.0%)\n",
      "  Expert 2 (PU expert): 338611456 calls ( 15.9%)\n",
      "  Expert 3 (shared): 475053440 calls ( 22.3%)\n",
      "  Expert 4 (shared): 260041328 calls ( 12.2%)\n",
      "  Expert 5 (shared): 268133904 calls ( 12.6%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 18.4%\n",
      "  âš ï¸ FAIR balance (deviation < 20%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 1350058339 tokens\n",
      "  Overflow rate: 117.75%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 2: base_model.encoder.block.2.layer.1.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 2128989440\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 125784536 calls (  5.9%)\n",
      "  Expert 1 (HI expert): 274535488 calls ( 12.9%)\n",
      "  Expert 2 (PU expert): 661003008 calls ( 31.0%)\n",
      "  Expert 3 (shared): 341302176 calls ( 16.0%)\n",
      "  Expert 4 (shared): 577784448 calls ( 27.1%)\n",
      "  Expert 5 (shared): 148579840 calls (  7.0%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 14.4%\n",
      "  âš ï¸ FAIR balance (deviation < 20%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 1323886662 tokens\n",
      "  Overflow rate: 115.47%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 3: base_model.encoder.block.3.layer.1.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 2128993792\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 529321824 calls ( 24.9%)\n",
      "  Expert 1 (HI expert): 164622272 calls (  7.7%)\n",
      "  Expert 2 (PU expert): 149072320 calls (  7.0%)\n",
      "  Expert 3 (shared): 126918856 calls (  6.0%)\n",
      "  Expert 4 (shared): 634970880 calls ( 29.8%)\n",
      "  Expert 5 (shared): 524087616 calls ( 24.6%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 13.2%\n",
      "  âš ï¸ FAIR balance (deviation < 20%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 1327137428 tokens\n",
      "  Overflow rate: 115.75%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 4: base_model.encoder.block.4.layer.1.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 2128991488\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 197376416 calls (  9.3%)\n",
      "  Expert 1 (HI expert): 644317952 calls ( 30.3%)\n",
      "  Expert 2 (PU expert): 194164752 calls (  9.1%)\n",
      "  Expert 3 (shared): 330889152 calls ( 15.5%)\n",
      "  Expert 4 (shared): 171048992 calls (  8.0%)\n",
      "  Expert 5 (shared): 591194432 calls ( 27.8%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 13.6%\n",
      "  âš ï¸ FAIR balance (deviation < 20%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 1245520043 tokens\n",
      "  Overflow rate: 108.63%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 5: base_model.encoder.block.5.layer.1.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 2128996992\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 173446976 calls (  8.1%)\n",
      "  Expert 1 (HI expert): 220716480 calls ( 10.4%)\n",
      "  Expert 2 (PU expert): 221394416 calls ( 10.4%)\n",
      "  Expert 3 (shared): 582745664 calls ( 27.4%)\n",
      "  Expert 4 (shared): 457643072 calls ( 21.5%)\n",
      "  Expert 5 (shared): 473050528 calls ( 22.2%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 10.7%\n",
      "  âš ï¸ FAIR balance (deviation < 20%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 1238257129 tokens\n",
      "  Overflow rate: 108.00%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 6: base_model.encoder.block.6.layer.1.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 2129014528\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 200861072 calls (  9.4%)\n",
      "  Expert 1 (HI expert): 278218784 calls ( 13.1%)\n",
      "  Expert 2 (PU expert): 535422720 calls ( 25.1%)\n",
      "  Expert 3 (shared): 571618048 calls ( 26.8%)\n",
      "  Expert 4 (shared): 459388416 calls ( 21.6%)\n",
      "  Expert 5 (shared): 83505376 calls (  3.9%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 12.7%\n",
      "  âš ï¸ FAIR balance (deviation < 20%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 1526617067 tokens\n",
      "  Overflow rate: 133.15%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 7: base_model.encoder.block.7.layer.1.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 2128987904\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 549500736 calls ( 25.8%)\n",
      "  Expert 1 (HI expert): 297396000 calls ( 14.0%)\n",
      "  Expert 2 (PU expert): 167032672 calls (  7.8%)\n",
      "  Expert 3 (shared): 155785152 calls (  7.3%)\n",
      "  Expert 4 (shared): 210464032 calls (  9.9%)\n",
      "  Expert 5 (shared): 748809280 calls ( 35.2%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 18.5%\n",
      "  âš ï¸ FAIR balance (deviation < 20%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 1253740214 tokens\n",
      "  Overflow rate: 109.35%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 8: base_model.decoder.block.0.layer.2.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 532246400\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 122803056 calls ( 23.1%)\n",
      "  Expert 1 (HI expert): 21173900 calls (  4.0%)\n",
      "  Expert 2 (PU expert): 33085102 calls (  6.2%)\n",
      "  Expert 3 (shared): 146013536 calls ( 27.4%)\n",
      "  Expert 4 (shared): 136856000 calls ( 25.7%)\n",
      "  Expert 5 (shared): 72314824 calls ( 13.6%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 12.7%\n",
      "  âš ï¸ FAIR balance (deviation < 20%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 396116583 tokens\n",
      "  Overflow rate: 134.92%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 9: base_model.decoder.block.1.layer.2.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 532240000\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 122617184 calls ( 23.0%)\n",
      "  Expert 1 (HI expert): 49535320 calls (  9.3%)\n",
      "  Expert 2 (PU expert): 78093224 calls ( 14.7%)\n",
      "  Expert 3 (shared): 90674656 calls ( 17.0%)\n",
      "  Expert 4 (shared): 93219184 calls ( 17.5%)\n",
      "  Expert 5 (shared): 98100416 calls ( 18.4%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 7.4%\n",
      "  âœ“ GOOD balance (deviation < 10%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 320718522 tokens\n",
      "  Overflow rate: 109.24%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 10: base_model.decoder.block.2.layer.2.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 532248128\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 84620496 calls ( 15.9%)\n",
      "  Expert 1 (HI expert): 87520536 calls ( 16.4%)\n",
      "  Expert 2 (PU expert): 92544008 calls ( 17.4%)\n",
      "  Expert 3 (shared): 89928816 calls ( 16.9%)\n",
      "  Expert 4 (shared): 89920360 calls ( 16.9%)\n",
      "  Expert 5 (shared): 87713944 calls ( 16.5%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 0.8%\n",
      "  âœ… EXCELLENT balance (deviation < 5%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 297984238 tokens\n",
      "  Overflow rate: 101.49%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 11: base_model.decoder.block.3.layer.2.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 532248320\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 88583848 calls ( 16.6%)\n",
      "  Expert 1 (HI expert): 91046920 calls ( 17.1%)\n",
      "  Expert 2 (PU expert): 92663400 calls ( 17.4%)\n",
      "  Expert 3 (shared): 84665080 calls ( 15.9%)\n",
      "  Expert 4 (shared): 86158104 calls ( 16.2%)\n",
      "  Expert 5 (shared): 89130944 calls ( 16.7%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 0.8%\n",
      "  âœ… EXCELLENT balance (deviation < 5%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 296970734 tokens\n",
      "  Overflow rate: 101.15%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 12: base_model.decoder.block.4.layer.2.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 532249152\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 83772272 calls ( 15.7%)\n",
      "  Expert 1 (HI expert): 92533384 calls ( 17.4%)\n",
      "  Expert 2 (PU expert): 90399176 calls ( 17.0%)\n",
      "  Expert 3 (shared): 83952080 calls ( 15.8%)\n",
      "  Expert 4 (shared): 92470544 calls ( 17.4%)\n",
      "  Expert 5 (shared): 89121744 calls ( 16.7%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 0.9%\n",
      "  âœ… EXCELLENT balance (deviation < 5%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 297758815 tokens\n",
      "  Overflow rate: 101.42%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 13: base_model.decoder.block.5.layer.2.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 532249248\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 84633120 calls ( 15.9%)\n",
      "  Expert 1 (HI expert): 90935392 calls ( 17.1%)\n",
      "  Expert 2 (PU expert): 91619408 calls ( 17.2%)\n",
      "  Expert 3 (shared): 86680928 calls ( 16.3%)\n",
      "  Expert 4 (shared): 86730672 calls ( 16.3%)\n",
      "  Expert 5 (shared): 91649704 calls ( 17.2%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 0.8%\n",
      "  âœ… EXCELLENT balance (deviation < 5%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 296619025 tokens\n",
      "  Overflow rate: 101.03%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 14: base_model.decoder.block.6.layer.2.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 532248384\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 90541160 calls ( 17.0%)\n",
      "  Expert 1 (HI expert): 87921432 calls ( 16.5%)\n",
      "  Expert 2 (PU expert): 89798008 calls ( 16.9%)\n",
      "  Expert 3 (shared): 88592880 calls ( 16.6%)\n",
      "  Expert 4 (shared): 90409744 calls ( 17.0%)\n",
      "  Expert 5 (shared): 84985144 calls ( 16.0%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 0.7%\n",
      "  âœ… EXCELLENT balance (deviation < 5%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 298073433 tokens\n",
      "  Overflow rate: 101.52%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "--- Layer 15: base_model.decoder.block.7.layer.2.DenseReluDense.moe_layer ---\n",
      "Total expert calls: 532247456\n",
      "\n",
      "Expert Usage Distribution:\n",
      "  Expert 0 (EN expert): 88088352 calls ( 16.6%)\n",
      "  Expert 1 (HI expert): 90670064 calls ( 17.0%)\n",
      "  Expert 2 (PU expert): 92877344 calls ( 17.5%)\n",
      "  Expert 3 (shared): 83920640 calls ( 15.8%)\n",
      "  Expert 4 (shared): 85623024 calls ( 16.1%)\n",
      "  Expert 5 (shared): 91067992 calls ( 17.1%)\n",
      "\n",
      "Load Balance Metrics:\n",
      "  Ideal usage per expert: 16.7%\n",
      "  Max deviation: 0.9%\n",
      "  âœ… EXCELLENT balance (deviation < 5%)\n",
      "\n",
      "Capacity Overflow:\n",
      "  Total overflow: 298814432 tokens\n",
      "  Overflow rate: 101.78%\n",
      "  âŒ HIGH overflow (> 10%) - consider increasing capacity_factor\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ All visualizations generated successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== VISUALIZE TRAINING RESULTS =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING VISUALIZATIONS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Plot training curves\n",
    "plot_training_curves(training_history)\n",
    "\n",
    "# Plot per-language performance\n",
    "plot_language_performance(language_rouge)\n",
    "\n",
    "# Analyze expert specialization\n",
    "analyze_expert_specialization(model)\n",
    "\n",
    "print(\"\\nâœ“ All visualizations generated successfully\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91f5e022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING FINAL MODEL AND RESULTS\n",
      "======================================================================\n",
      "\n",
      "âœ“ Model saved to: ./checkpoints/final_model_20251117_030731/model_final.pt\n",
      "âœ“ Results saved to: final_results_20251117_030731.json\n",
      "\n",
      "======================================================================\n",
      "FINAL TRAINING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  Model: google/mt5-small\n",
      "  Learning Rate: 3.00e-02\n",
      "  Epochs: 10\n",
      "  Effective Batch Size: 64\n",
      "\n",
      "Training Results:\n",
      "  Training Time: 4.85 hours\n",
      "  Final Train Loss: 0.8987\n",
      "  Final Val Loss: 1.2999\n",
      "\n",
      "Test Results:\n",
      "  Overall ROUGE-1: 0.1752\n",
      "  Overall ROUGE-2: 0.0501\n",
      "  Overall ROUGE-L: 0.1285\n",
      "\n",
      "Per-Language ROUGE-L:\n",
      "  EN: 0.2291\n",
      "  HI: 0.0107\n",
      "  PA: 0.0122\n",
      "\n",
      "======================================================================\n",
      "âœ“ TRAINING PIPELINE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "âœ“ Model saved to: ./checkpoints/final_model_20251117_030731/model_final.pt\n",
      "âœ“ Results saved to: final_results_20251117_030731.json\n",
      "\n",
      "======================================================================\n",
      "FINAL TRAINING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  Model: google/mt5-small\n",
      "  Learning Rate: 3.00e-02\n",
      "  Epochs: 10\n",
      "  Effective Batch Size: 64\n",
      "\n",
      "Training Results:\n",
      "  Training Time: 4.85 hours\n",
      "  Final Train Loss: 0.8987\n",
      "  Final Val Loss: 1.2999\n",
      "\n",
      "Test Results:\n",
      "  Overall ROUGE-1: 0.1752\n",
      "  Overall ROUGE-2: 0.0501\n",
      "  Overall ROUGE-L: 0.1285\n",
      "\n",
      "Per-Language ROUGE-L:\n",
      "  EN: 0.2291\n",
      "  HI: 0.0107\n",
      "  PA: 0.0122\n",
      "\n",
      "======================================================================\n",
      "âœ“ TRAINING PIPELINE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== SAVE FINAL MODEL AND RESULTS =====\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING FINAL MODEL AND RESULTS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save model checkpoint\n",
    "final_checkpoint_path = f\"./checkpoints/final_model_{timestamp}\"\n",
    "os.makedirs(final_checkpoint_path, exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': config.__dict__,\n",
    "    'training_history': training_history,\n",
    "    'test_results': {\n",
    "        'overall': overall_rouge,\n",
    "        'per_language': language_rouge\n",
    "    },\n",
    "    'timestamp': timestamp\n",
    "}, f\"{final_checkpoint_path}/model_final.pt\")\n",
    "\n",
    "print(f\"âœ“ Model saved to: {final_checkpoint_path}/model_final.pt\")\n",
    "\n",
    "# Save detailed results as JSON\n",
    "final_results = {\n",
    "    'timestamp': timestamp,\n",
    "    'configuration': {\n",
    "        'learning_rate': float(config.learning_rate),\n",
    "        'batch_size': config.batch_size,\n",
    "        'gradient_accumulation_steps': config.gradient_accumulation_steps,\n",
    "        'effective_batch_size': config.batch_size * config.gradient_accumulation_steps,\n",
    "        'num_epochs': config.num_epochs,\n",
    "        'warmup_steps': config.warmup_steps,\n",
    "        'weight_decay': float(config.weight_decay),\n",
    "        'gradient_clip_val': float(config.gradient_clip_val),\n",
    "        'aux_loss_weight_end': float(config.aux_loss_weight_end),\n",
    "        'expert_dropout': float(config.expert_dropout),\n",
    "        'num_experts': config.num_experts,\n",
    "        'top_k': config.top_k,\n",
    "    },\n",
    "    'training': {\n",
    "        'train_losses': [float(x) for x in training_history['train_losses']],\n",
    "        'val_losses': [float(x) for x in training_history['val_losses']],\n",
    "        'val_rouge_scores': training_history['val_rouge_scores'],\n",
    "        'training_time_hours': training_history['training_time'] / 3600,\n",
    "        'curriculum_phases': [p for p in training_history.get('phases', [])]\n",
    "    },\n",
    "    'test_results': {\n",
    "        'overall': {\n",
    "            'rouge1': float(overall_rouge['rouge1']),\n",
    "            'rouge2': float(overall_rouge['rouge2']),\n",
    "            'rougeL': float(overall_rouge['rougeL'])\n",
    "        },\n",
    "        'per_language': {\n",
    "            lang: {\n",
    "                'rouge1': float(scores['rouge1']),\n",
    "                'rouge2': float(scores['rouge2']),\n",
    "                'rougeL': float(scores['rougeL'])\n",
    "            }\n",
    "            for lang, scores in language_rouge.items()\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results_path = f\"final_results_{timestamp}.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Results saved to: {results_path}\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TRAINING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Model: {config.model_name}\")\n",
    "print(f\"  Learning Rate: {config.learning_rate:.2e}\")\n",
    "print(f\"  Epochs: {config.num_epochs}\")\n",
    "print(f\"  Effective Batch Size: {config.batch_size * config.gradient_accumulation_steps}\")\n",
    "\n",
    "print(f\"\\nTraining Results:\")\n",
    "print(f\"  Training Time: {training_history['training_time']/3600:.2f} hours\")\n",
    "print(f\"  Final Train Loss: {training_history['train_losses'][-1]:.4f}\")\n",
    "print(f\"  Final Val Loss: {training_history['val_losses'][-1]:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Overall ROUGE-1: {overall_rouge['rouge1']:.4f}\")\n",
    "print(f\"  Overall ROUGE-2: {overall_rouge['rouge2']:.4f}\")\n",
    "print(f\"  Overall ROUGE-L: {overall_rouge['rougeL']:.4f}\")\n",
    "\n",
    "print(f\"\\nPer-Language ROUGE-L:\")\n",
    "for lang, scores in language_rouge.items():\n",
    "    print(f\"  {lang.upper()}: {scores['rougeL']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ“ TRAINING PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
